{"posts":[{"title":"Bonjour 不 Bon：修复 Bonjour 中存在的 IPv6 栈溢出 bug","text":"闲话少说，如果你在使用基于由 Apple 提供的 Bonjour 协议的服务（例如通过网络刷新 AltStore 应用，iTunes WiFi 同步等）时遇到无法正常连接的问题，并且查看 Windows 事件查看器的 Windows 日志中发现此应用程序错误（异常代码和错误偏移量一致）： 1234567891011错误应用程序名称: mDNSResponder.exe，版本: 3.1.0.1，时间戳: 0x55cbcce6错误模块名称: mDNSResponder.exe，版本: 3.1.0.1，时间戳: 0x55cbcce6异常代码: 0xc0000409错误偏移量: 0x00000000000437c3错误进程 ID: 0x0x9BA8错误应用程序启动时间: 0x0x1DB1204029AD2A1错误应用程序路径: C:\\Program Files\\Bonjour\\mDNSResponder.exe错误模块路径: C:\\Program Files\\Bonjour\\mDNSResponder.exe报告 ID: 97706ac4-91ee-484e-a851-e12e37433bd0错误程序包全名: 错误程序包相对应用程序 ID: 那么下载这个修复后的 mDNSResponder.exe，替换掉 C:\\Program Files\\Bonjour\\mDNSResponder.exe，然后去服务里重启 Bonjour 服务即可。如果是 AltStore 刷新不了的问题，还需要在这之后重启 Altserver。 问题背景 之前我在 Windows 上用代理软件一般不打开系统代理等设置，只通过 port 访问，然后通过 proxifier 或者手动设置 HTTP 代理（一般是命令行）方式访问代理。然而这种方式会带来一些问题：最主要就是有的软件用 HTTP 连不上用 SOCKS 却可以，或者反过来的情况，这就导致规则很难设置；还有就是有的规则要用全局有点规则要用分流导致要同时开两个代理软件等等。proxifier 有时候又会出现莫名奇妙地无法代理的问题，然后它这个软件原理又比较奇妙很难查明原因（不是用的系统设置中的代理设置，也没有创建网卡，感觉更像是注入），比如我最近代理 VRChat 的时候就有时候能用有时候用不了，查了半天也找不到原因… 之所以一直用着是一是因为我希望 Windows 上的软件尽量不走代理，我大部分的代理需求都来自浏览器，已经被 SmartProxy 这类扩展解决了，proxifier主要还是解决 Discord 这类不用代理就连不上的软件，或者 GitHub 这类域名等；二是因为我的系统上还有 Tailscale、Altserver 之类对本地网络由依赖的软件，我不太清楚用 TUN 这类方式会不会对它们造成干扰。 不过最近捣鼓 iOS 代理软件让我开始觉得 TUN 这种网络层代理才是更完美的代理方法，所以最终还是把 Windows 也换成了 TUN 代理模式。我目前用的代理软件是 Mihomo Party，内核是 Mihomo。 没过几天我就发现 AltStore 刷新软件时找不到 Altserver，Altserver 中也不显示 iOS 设备了。很快我就意识到这很可能是我前几天弄成 TUN 代理导致的。 我尝试关闭代理软件，这会删除创建的 TUN 网卡，然后重启 Altserver，但很奇怪的并没有作用。之前我遇到几次 Altserver 连接问题发现通过重启 Apple Mobile Device Service 服务可以修复，然而我尝试了很多次也没有作用。 然后我找到了这个 issue，于是尝试关闭代理自启然后重启，此时连接恢复正常。但打开代理软件后，刚开始 AltStore 还可以正常刷新，过一会之后就又连不上了。 抓包分析 因为 AltServer 通过网络刷新应用需要通过 iTunes 开启 iOS 设备的“通过Wi-Fi 与此设备同步”选项，我知道它的工作原理其实是通过 Bonjour 协议发现设备。猜想是不是 Bonjour 协议在开了 TUN 之后不走物理网卡设备，或者 TUN 向 物理网卡转发导致了问题（我对 TUN 代理的工作原理不太熟悉，所以有很多猜想并不合理）。总之我打算用 Wireshark 抓包看下具体情况。 首先要说的是 Apple 的 Bonjour 协议本质上就是 mDNS（Multicast DNS）协议，走 UDP 的5353端口。当 mDNS 客户端需要解析主机名时，它会发送一条 IP 多播查询消息，要求具有该名称的主机识别自己的身份。然后，该目标机器多播一条包含其 IP 地址的消息。[1] 我先在 Bonjour 正常工作的情况下抓了下包，mDNS 在 IPv4/v6 下面都会工作，但目前我先只看 IPv4 的情况，于是我设置过滤规则 mdns &amp;&amp; ip.addr == 192.168.2.100 || mdns &amp;&amp; ip.addr == 192.168.2.16，192.168.2.100 是电脑的 IP，192.168.2.16 是 iOS 设备的 IP。 很快我就发现了目标，一些和 Altserver 有关的 mDNS 查询和回复： 1234567891011121314151617181920212223242526272829303132333435363738394041Internet Protocol Version 4, Src: 192.168.2.16, Dst: 224.0.0.251User Datagram Protocol, Src Port: 5353, Dst Port: 5353Multicast Domain Name System (query) Transaction ID: 0x0000 [Expert Info (Warning/Protocol): DNS response missing] Flags: 0x0000 Standard query Questions: 1 Answer RRs: 0 Authority RRs: 0 Additional RRs: 0 Queries MDDPC._altserver._tcp.local: type SRV, class IN, &quot;QU&quot; question Name: MDDPC._altserver._tcp.local [Name Length: 27] [Label Count: 4] Type: SRV (33) (Server Selection) .000 0000 0000 0001 = Class: IN (0x0001) 1... .... .... .... = &quot;QU&quot; question: TrueInternet Protocol Version 4, Src: 192.168.2.100, Dst: 224.0.0.251User Datagram Protocol, Src Port: 5353, Dst Port: 5353Multicast Domain Name System (response) Transaction ID: 0x0000 [Expert Info (Warning/Protocol): DNS response retransmission. Original response in frame 21609] Flags: 0x8400 Standard query response, No error Questions: 0 Answer RRs: 1 Authority RRs: 0 Additional RRs: 7 Answers MDDPC._altserver._tcp.local: type SRV, class IN, cache flush, priority 0, weight 0, port 1382, target MDDPC.local Additional records MDDPC.local: type A, class IN, cache flush, addr 192.168.2.100 MDDPC.local: type AAAA, class IN, cache flush, addr 2001:0db8:85a3:0000:0000:8a2e:0370:7334 MDDPC.local: type AAAA, class IN, cache flush, addr 2001:0db8:85a3:0000:0000:abcd:ef12:3456 MDDPC.local: type AAAA, class IN, cache flush, addr 2001:0db8:85a3:0000:1234:5678:9abc:def0 MDDPC.local: type AAAA, class IN, cache flush, addr fe80::1a2b:3c4d:5e6f:7890 MDDPC.local: type NSEC, class IN, cache flush, next domain name MDDPC.local MDDPC._altserver._tcp.local: type NSEC, class IN, cache flush, next domain name MDDPC._altserver._tcp.local [Retransmitted response. Original response in: 21609] [Retransmission: True] 首先可以看到这两个报文的目的地址都是 224.0.0.251，这是固定的 mDNS 多播 IP 地址。iOS 设备向我的计算机（MDDPC）请求了 _altserver 这一 TCP 服务。而应答中返回了该服务的端口为 1382，通过 MDDPC.local 这一域名访问，同时在 Additional records 中将该域名对应的 IP 均列了出来。这就是 mDNS 大致的工作原理了。 接下来我在开启 TUN 的情况下进行抓包，由于此时多了一个 TUN 网卡，所以我分别同时在物理网卡和 TUN 网卡上同时进行抓包。 我在 TUN 网卡上确实抓到了一些 mDNS 包，但是没有和 Altserver 有关的包，而且都是计算机自己发送的，没有其他人响应。因为其实 TUN 网卡和物理网卡不在一个网段上，如下，物理网卡网段为 192.168，TAP 网卡为 198.18： 1234567891011121314151617181920212223242526272829303132333435363738394041未知适配器 Mihomo: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Meta Tunnel 物理地址. . . . . . . . . . . . . : AA-BB-CC-DD-EE-FF DHCP 已启用 . . . . . . . . . . . : 否 自动配置已启用. . . . . . . . . . : 是 IPv6 地址 . . . . . . . . . . . . : 2001:0db8:abcd::1(首选) IPv4 地址 . . . . . . . . . . . . : 198.18.0.1(首选) 子网掩码 . . . . . . . . . . . . : 255.255.255.252 默认网关. . . . . . . . . . . . . : :: 0.0.0.0 DNS 服务器 . . . . . . . . . . . : 2001:0db8:abcd::2 198.18.0.2 TCPIP 上的 NetBIOS . . . . . . . : 已启用以太网适配器 以太网: 连接特定的 DNS 后缀 . . . . . . . : 描述. . . . . . . . . . . . . . . : Intel(R) Ethernet Controller I226-V 物理地址. . . . . . . . . . . . . : 11-22-33-44-55-66 DHCP 已启用 . . . . . . . . . . . : 否 自动配置已启用. . . . . . . . . . : 是 IPv6 地址 . . . . . . . . . . . . : 2001:0db8:abcd::100(首选) 获得租约的时间 . . . . . . . . . : 2024年9月28日 21:37:00 租约过期的时间 . . . . . . . . . : 2024年9月30日 6:30:44 IPv6 地址 . . . . . . . . . . . . : 2001:0db8:abcd::200(首选) 临时 IPv6 地址. . . . . . . . . . : 2001:0db8:abcd::300(受到抨击) 临时 IPv6 地址. . . . . . . . . . : 2001:0db8:abcd::400(首选) 本地链接 IPv6 地址. . . . . . . . : fe80::1a2b:3c4d:5e6f:7890%21(首选) IPv4 地址 . . . . . . . . . . . . : 192.168.2.100(首选) 子网掩码 . . . . . . . . . . . . : 255.255.255.0 默认网关. . . . . . . . . . . . . : fe80::8ede:f9ff:fead:6d81%21 192.168.2.1 DHCPv6 IAID . . . . . . . . . . . : 554221496 DHCPv6 客户端 DUID . . . . . . . : 00-01-00-01-2C-28-7A-02-11-22-33-44-55-66 DNS 服务器 . . . . . . . . . . . : 2001:0db8::1 2001:0db8::2 119.29.29.29 223.5.5.5 TCPIP 上的 NetBIOS . . . . . . . : 已启用 在物理网卡上我抓到了来自 iOS 对 Altserver 的 mDNS 查询请求，但计算机并没有响应。 谁是 Bonjour？ 到这里我想看下到底是谁在监听5353端口，通过 netstat -abn 我发现监听 UDP 5353端口的程序不止一个，不太确定 Apple 的 Bonjour 由谁回复： 123456789 [svchost.exe] UDP 0.0.0.0:5353 *:* [chrome.exe] UDP 0.0.0.0:5353 *:* [svchost.exe] UDP 192.168.2.100:5353 *:* [nvcontainer.exe] UDP 192.168.2.100:5353 *:*... 于是我直接打开 Process Hacker 搜索 Bonjour，很快发现了一个叫做 mDNSResponder.exe 的程序，父进程是 services.exe ，他就是 Bonjour 服务。路径是 C:\\Program Files\\Bonjour\\mDNSResponder.exe。 打开 TUN 代理后，我发现 mDNSResponder.exe 很快就退出了。C:\\Program Files\\Bonjour\\ 目录下也没有发现有 log。因此我就去系统日志中寻找，于是找到了文章开头的错误日志。 看起来 mDNSResponder.exe 并非正常退出，否则一般也不会触发日志记录，并且是应用程序崩溃事件。这也解释了为什么关闭代理也无法恢复正常：Bonjour 服务并不会自动重启。在我关闭代理并手动启动 Bonjour 服务和 Altserver 后，果然一切恢复了正常。搜了下网上还有其他人也遇到过相同的错误：Bonjour Service Crashes when Eddie Active - Off-Topic - AirVPN 另外我发现 Clash for Windows 的 TUN 代理并不会导致 Bonjour 服务崩溃，这说明问题很可能并不出在 TUN 本身上。我又尝试更改 TUN 模式的设置，比如设置堆栈，自动全局路由，严格路由，DNS 劫持等等，但不管怎么改 mDNSResponder.exe 都会崩溃。 逆向时间 为了搞明白问题出在哪里，我准备上 x64dbg 上分析一下。不过 mDNSResponder.exe 默认情况下是以服务程序模式执行的，没办法直接执行： 12PS C:\\Users\\Fusion\\Downloads&gt; C:\\'Program Files'\\Bonjour\\mDNSResponder.exestart service dispatcher failed (1063) 不过好在它提供了选项 -server 可以用于直接执行： 1234567891011mDNSResponder 1.0d1 &lt;no args&gt; Runs the service normally -install Creates the service and starts it -remove Stops the service and deletes it -start Starts the service dispatcher after processing all other arguments -server Runs the service directly as a server (for debugging) -q Toggles Quiet Mode (no events or output) -remote Allow remote connections -cache n Number of mDNS cache entries (defaults to 512) -h[elp] Display Help/Usage 在 x64dbg 中添加参数 -server 后，就可以正常调试了。我发现它启动后很快触发了一个异常： 123456789101112EXCEPTION_DEBUG_INFO: dwFirstChance: 1 ExceptionCode: C0000005 (EXCEPTION_ACCESS_VIOLATION) ExceptionFlags: 00000000 ExceptionAddress: mdnsresponder.[00007FF64BE59D37](x64dbg://localhost/address64#00007FF64BE59D37) NumberParameters: 2 ExceptionInformation[00]: [0000000000000001](x64dbg://localhost/address64#0000000000000001) Write ExceptionInformation[01]: [0000000000150000](x64dbg://localhost/address64#0000000000150000) Inaccessible Address 第一次异常于 [00007FF64BE59D37](x64dbg://localhost/address64#00007FF64BE59D37) (C0000005, EXCEPTION_ACCESS_VIOLATION)# 出错的指令00007FF64BE59D37 | 41:8810 | mov byte ptr ds:[r8],dl | r8:&quot;Actx &quot; mov 指令访问了一个不可访问的地址，这个地址就是 r8 寄存器里的 0x150000，mov 试图将 dl 寄存器的内容写到这个地址。 这个地址是哪里呢，查看内存布局，可以看到该地址正好位于堆栈上方的只读内存段的开头。结合汇编和在 x64dbg 下的调试，这大概率是一个栈溢出错误。 于是打开 IDA 开始分析，找到出错位置的伪代码如下： 12345678910111213141516if ( memcmp(src, sa_family, i-&gt;Address.iSockaddrLength) ) { stack_mem_to_set_ff = 0i64; v56 = 0i64; stack_addr = &amp;stack_mem_to_set_ff; do { if ( PrefixLength &lt; 8 ) val_ff = -1 &lt;&lt; (8 - PrefixLength); else val_ff = -1; *(_BYTE *)stack_addr = val_ff;// crash here stack_addr = (__int64 *)((char *)stack_addr + 1); PrefixLength -= 8; } while ( PrefixLength ); 上面代码已经被我解析过，比较容易能看到问题原因：PrefixLength 在非8的倍数时 while 循环永远不会结束，并且 PrefixLength 是一个 unsigned int，所以会把 stack_mem_to_set_ff 所在栈位置以上内存填充 FF，直到超过栈范围写入只读地址导致崩溃。 那么 PrefixLength 又是什么？这就要提到这部分代码开头调用的 GetAdaptersAddresses API了。 12345678910111213141516AdaptersAddresses = GetAdaptersAddresses( 0, 0x3Eu, // 返回单播地址,返回此适配器上的 IP 地址前缀列表,返回默认网关的地址等 0i64, // Reserved pLinkList_of_IP_ADAPTER_ADDRESSES, &amp;Size);pFirstPrefix = pLinkList_of_IP_ADAPTER_ADDRESSES_unwind2-&gt;FirstPrefix;IPHLPAPI_DLL_LINKAGE ULONG GetAdaptersAddresses( [in] ULONG Family, [in] ULONG Flags, [in] PVOID Reserved, [in, out] PIP_ADAPTER_ADDRESSES AdapterAddresses, [in, out] PULONG SizePointer); 这个函数的定义具体见：GetAdaptersAddresses function (iphlpapi.h) - Win32 apps | Microsoft Learn，简单来说它会返回系统中所有网卡的详细信息。其中 0x3E 为 Flags 参数，其中有一位是 GAA_FLAG_INCLUDE_PREFIX，表示要求系统返回 IPv6 和 IPv4 地址的 IP 地址前缀。所有程序调用这个 API 返回的内容应该是一样的，所以我在 Visual Studio 中写了个测试程序调用该 API 来 debug。PIP_ADAPTER_ADDRESSES-&gt;FirstPrefix 中保存的就是这些前缀了，对于 mihomo TUN 内容如下： 可以看到所有 Prefix 通过 next 链接在一起，第二层 PrefixLength 为 0x7e 的 Prefix 就是问题所在，它并非8的倍数。 另外观察 FirstPrefix-&gt;Address.lpSockaddr-&gt;sa_family 成员，值为 0x2 代表 IPv4，0x17 代表 IPv6。lpSockaddr 这个成员是一个指向 sockaddr 结构体的指针，这个结构体长度根据所选协议不同而有所不同，具体长度储存在 Address.iSockaddrLength中，但第一个成员永远是地址族。 网卡 IP 地址储存在 PIP_ADAPTER_ADDRESSES-&gt;FirstUnicastAddress 中，其结构和 Prefix 类似，由于网卡可能有多个 IP 地址，其也有多个 sockaddr 结构，通过链表组织在一起。 整体代码的逻辑是遍历所有网卡-&gt;遍历网卡的所有 IP 地址-&gt;遍历网卡所有地址前缀。其作用为找到所有网卡的所有IP对应的子网前缀。出错代码位于遍历网卡所有地址前缀的逻辑内，并且仅在 IP 地址为 IPv6 时才会执行，功能为生成前缀对应的掩码来计算子网前缀。 这也就解释了为什么 Clash for Windows 的 TAP 模式不会崩溃，因为即便打开了 IPv6 功能，它的 TAP 网卡依然没有 IPv6 地址，因此就不会执行到错误处。下图为 Clash TAP 的 FirstUnicastAddress，可以看到只有一个 IPv4 类型的地址： 那么如果关闭 mihomo 的 IPv6 功能呢？我测试了一下也不会报错，但查看网卡仍然有 IPv6 地址，此时查看所有 IPv6 Prefix 发现不再有非8倍数的 PrefixLength 了。另外物理网卡自动分配的 Prefix 长度也均为8的倍数。 问题的解决方案也很简单，只要将生成掩码的循环的判断条件从不为0修改为大于0即可。对应到汇编代码即将下图的 jne 指令修改为 jg，对应到程序文件就是将 0x9140 偏移处的 75 修改为 7F。 后话 修好这个问题后我又去找了下，Bonjour 的源码其实已经被 Apple 公开了，感兴趣的可以去看下： mDNSResponder/mDNSWindows at main · apple-oss-distributions/mDNSResponder · GitHub 本篇文章分析的代码对应的是 mDNSWin32.c 中的 getifaddrs_ipv6。该库中最新代码已经修复了这个问题。然而我并不知道这个修复的版本被用在了哪里，Bonjour 本身似乎并没有独立的安装包，我系统中的 Bonjour 是安装非 Windows 商店版本的 iTunes 时自带的（因为 Altserver 不支持商店版 iTunes）。也许是用在了现在商店版本的“Apple 设备”这个软件中？ 另外，我还尝试构建了下这个最新的开源版本，很不幸并没有构建成功。如果可以的话还想试下用最新版本的 Bonjour 替换下，现在这个版本修改日期还是15年的，算下来都快10年了（天呐）。 那么就到这里吧，这些工作都是我一晚上肝出来的，说实话开始时没想到会走到通过逆向把它修好这步，感觉学到很多。 参考 Multicast DNS - Wikipedia ↩︎","link":"/2024/09/29/bonjour_fix/"},{"title":"CFS调度器、权重、优先级与虚拟时钟","text":"盘一盘在学习 CFS 调度器过程中的一些感想。 施工中！！！ 咕咕咕！","link":"/2023/04/20/cfs_weight_nice/"},{"title":"Apple Clangd 掉坑记","text":"clangd 是 llvm 项目推出的 C/C++ 语言服务器，通过 LSP（Language Server Protocal）协议向编辑器如 vscode/vim/emacs 提供语法补全、错误检测、跳转、格式化等等功能。据说是比 vscode 自己的 IntelliSense 更好一些，我开始用 clangd 的时候 IntelliSense 貌似还不支持使用 compile_commands.js 文件辅助代码分析，因此并没有具体对比过两者的差异。 macOS 上附带的 llvm 是 Apple 自己管理的，属于 Xcode 的一部分，这个版本其实是落后于主线版本很多的。理论上来说这种等待上游稳定后再选择使用的版本稳定性更好，问题会比较少，然而意外的这次在更新了 Xcode 后 clangd 就翻车了。 我个人比较喜欢在 vscode 上配合 clangd 插件阅读内核代码（虽然在工作时只能用 vim + ctags 这种古朴的方式，不过 tag 文件确实更灵活些，尤其是需要看不同架构的代码实现时）。为了获得更精确的分析，一般我会在 make 时配合 bear 生成 compile_commands.js 文件，用于辅助 clangd 语法分析。这样几乎所有符号都能正确解析，对分析代码有很大的帮助。并且分析过程不需要编译，可以把 compile_commands.js 文件稍微修改一下，拿到其他安装了 llvm 的平台上也可以工作的很好。 前几天 Xcode 在后台自动更新了，今天打开 vscode 时顺手更新了下 vscode，重新启动后 clangd 提供的代码分析功能就完全坏掉了。 一开始 clangd 一直在报 Error while reading shard xxx.c: wrong version: want 17, got 16 这个错。我猜测可能是更新了 Xcode 后缓存的某些文件的版本和当前不符导致的，于是删除了项目目录下的 .cache .tmp_* 之类的文件，然后这个报错就消失了，但是 clangd 插件还是报告崩溃（我也很崩溃… 打开输出窗口看了下 clangd 插件的日志，报了一个 Signalled during AST worker action: InlayHints 错误，看起来是被某个信号中断了（其实当时通过这个大概能推测到是某个 bug 导致访问了非法内存地址）。这里 InlayHints 其实指的就是 vscode 中指针处在符号上方后会跳出来的悬浮嵌入提示，也就是 clangd 插件向 clangd server 请求提示信息时发生的错误。 Google 了下只找到了一个似乎比较符合目前情况的 issue，很巧的是他也是在用 clangd 分析内核代码时出现的（而且是访问了空指针导致的）。 不过我的输出中并没有栈回溯，不知道是不是 Apple 版的 clangd 去掉了栈回溯打印，因此还不能完全确定就是同一个问题。不过他提到了错误是 EXPORT_SYMBOL 宏展开后的代码导致的问题，因此我只留下两个没有 EXPORT_SYMBOL 宏的源文件，重启 vscode… 这次并没有崩溃，嵌入提示也在这个源文件中正常工作了。目前差不多能确定是同一个问题了，为了再次确认下，我想到既然他自己不打印，我可以挂 lldb 自己看啊～ 只见我一个 attach，马上抓到了内存访问异常—— 直接贴一下内容： 1234567891011121314151617181920212223(lldb) cProcess 27639 resumingProcess 27639 stopped* thread #15, name = 'ASTWorker:dev.c', stop reason = EXC_BAD_ACCESS (code=1, address=0x8) frame #0: 0x0000000109a31953 clangd`clang::RecursiveASTVisitor&lt;clang::clangd::(anonymous namespace)::InlayHintVisitor&gt;::TraverseDecl(clang::Decl*) + 12051clangd`clang::RecursiveASTVisitor&lt;clang::clangd::(anonymous namespace)::InlayHintVisitor&gt;::TraverseDecl:-&gt; 0x109a31953 &lt;+12051&gt;: movl 0x8(%rdx), %edx 0x109a31956 &lt;+12054&gt;: movq %r13, %rdi 0x109a31959 &lt;+12057&gt;: movq %r15, %rsi 0x109a3195c &lt;+12060&gt;: callq 0x109a4dcf0 ; clang::clangd::(anonymous namespace)::InlayHintVisitor::addReturnTypeHint(clang::FunctionDecl*, clang::SourceLocation)Target 0: (clangd) stopped.(lldb) bt* thread #15, name = 'ASTWorker:dev.c', stop reason = EXC_BAD_ACCESS (code=1, address=0x8) * frame #0: 0x0000000109a31953 clangd`clang::RecursiveASTVisitor&lt;clang::clangd::(anonymous namespace)::InlayHintVisitor&gt;::TraverseDecl(clang::Decl*) + 12051 frame #1: 0x0000000109a31cb8 clangd`clang::RecursiveASTVisitor&lt;clang::clangd::(anonymous namespace)::InlayHintVisitor&gt;::TraverseDecl(clang::Decl*) + 12920 frame #2: 0x0000000109a2e680 clangd`clang::clangd::inlayHints(clang::clangd::ParsedAST&amp;, llvm::Optional&lt;clang::clangd::Range&gt;) + 336 frame #3: 0x0000000109949909 clangd`void llvm::detail::UniqueFunctionBase&lt;void, llvm::Expected&lt;clang::clangd::InputsAndAST&gt; &gt;::CallImpl&lt;clang::clangd::ClangdServer::inlayHints(llvm::StringRef, llvm::Optional&lt;clang::clangd::Range&gt;, llvm::unique_function&lt;void (llvm::Expected&lt;std::__1::vector&lt;clang::clangd::InlayHint, std::__1::allocator&lt;clang::clangd::InlayHint&gt; &gt; &gt;)&gt;)::$_21&gt;(void*, llvm::Expected&lt;clang::clangd::InputsAndAST&gt;&amp;) + 89 frame #4: 0x0000000109af3ae4 clangd`void llvm::detail::UniqueFunctionBase&lt;void&gt;::CallImpl&lt;clang::clangd::(anonymous namespace)::ASTWorker::runWithAST(llvm::StringRef, llvm::unique_function&lt;void (llvm::Expected&lt;clang::clangd::InputsAndAST&gt;)&gt;, clang::clangd::TUScheduler::ASTActionInvalidation)::$_7&gt;(void*) + 1524 frame #5: 0x0000000109aeb56a clangd`clang::clangd::(anonymous namespace)::ASTWorker::runTask(llvm::StringRef, llvm::function_ref&lt;void ()&gt;) + 522 frame #6: 0x0000000109ae953a clangd`void llvm::detail::UniqueFunctionBase&lt;void&gt;::CallImpl&lt;clang::clangd::(anonymous namespace)::ASTWorker::create(llvm::StringRef, clang::clangd::GlobalCompilationDatabase const&amp;, clang::clangd::TUScheduler::ASTCache&amp;, clang::clangd::TUScheduler::HeaderIncluderCache&amp;, clang::clangd::AsyncTaskRunner*, clang::clangd::Semaphore&amp;, clang::clangd::TUScheduler::Options const&amp;, clang::clangd::ParsingCallbacks&amp;)::$_4&gt;(void*) + 4250 frame #7: 0x0000000109c6ec37 clangd`void* llvm::thread::ThreadProxy&lt;std::__1::tuple&lt;clang::clangd::AsyncTaskRunner::runAsync(llvm::Twine const&amp;, llvm::unique_function&lt;void ()&gt;)::$_4&gt; &gt;(void*) + 71 frame #8: 0x00007ff811b31259 libsystem_pthread.dylib`_pthread_start + 125 frame #9: 0x00007ff811b2cc7b libsystem_pthread.dylib`thread_start + 15 和这个 issue 的栈回溯基本完全一致，到此我们确认了问题。 不过我还有最后一个疑问，这个 issue 被提出来的时间距今已过去一年了。我确认了下 clangd 的版本，clangd 的版本号和 clang 是一致的，我系统中的版本目前是 14.0.3。目前 llvm 主线已经到 16.0.4 了，而主线的 14.0.3 是在2022年4月29日发布的。也就是说 Apple 的 llvm 落后于主线大概一年，而这个问题的修复 commit 刚好在 14.0.3 发布的一周后，也就是说并不包括在 14.0.3 中。不过话说这么久的必现崩溃问题不应该早就向后移植了吗，难道 Apple 的 llvm 团队在更新的时候只把编译器相关的问题向后移植了下，这个小小（？）的 clangd 问题就忽略了？ 又去这个网站看了下 Xcode 版本对应的 Clang 版本，最新一次 Xcode 更新确实将 clang 从 14.0.0 更新到了 14.0.3，这一切也就说得通了。 最后我用 brew 安装了最新的 llvm 版本解决了这个问题。不过默认 brew 安装的版本并不会出现在 PATH 中（这点很好，毕竟 macOS 上 Xcode 之类主要用的还是这个版本，并且安装时也提示了混用版本可能出现问题），需要在 VScode 的 clangd 插件里指定了下使用 brew 安装的 /usr/local/opt/llvm/bin/clangd 路径上的 clangd。 终于，clangd 愉快的跑了起来，vscode 的嵌入提示也能正常显示了！ 这个问题也让我想到了之前看到老雷发现的 Visual Studio 问题也是访问空指针（具体在这），即便是大公司发布的看起来可靠稳定的开发工具有时候还是会出 bug 的 ^ ^","link":"/2023/05/19/clangd_vsc_fault/"},{"title":"一次 Linux 5.4 内核启动失败分析","text":"在我司一台 x86 服务器上遇到了一个奇怪的问题：这台服务器上一直以来使用的是从 linux-stable 主线的 lts 版本自行编译的内核，具体来说使用的是5.15.15版本内核。 由于驱动需要我尝试在上面编译和引导5.4.172内核，但无法正常启动，内核打印显示找不到任何分区。初步判断是硬盘控制器驱动没有加载，但是驱动已经以模块形式编译了（该服务器使用的是一个博通 RAID 控制器，对应驱动为 megaraid_sas）。 无奈我尝试将该驱动编译到内核，这次内核成功找到了所有分区，但却无法找到内核 cmdline 指定的 rootfs uuid： 12345678910111213VFS: Cannot open root device &quot;UUID=xxxxxxxxx&quot; or unknown-block(0,0): error -6Please append a correct &quot;root=&quot; boot option; here are the available partitions:0800 34441003008 sdadriver: sd0801 14680000 sda1 afc0d02a-b8be-407c-8ac6-ob3ac86a26d0802 101376 sda2 eef76d84-e51a-49cb-b16b-a76fa7155b130803 16384 sda3 df9f72aa-cb58-blab-bl48f56be2690804 22021166 sda4 c11f17f3-7ac6-l667-aaf0-a748cfbc193d0805 31236209184 sda5 yyyyyyyyyyKernel panic - not syncing: VFS: Unable to mount root fs on unknown-block(0,0)CPU:31 PID:1 comm swapper/0 Not tainted 5.4.172 #14Hardware name: Dell Inc. PowerEdge R750/04V528, BIOS 1.7.4 06/27/2022 这里 rootfs 为 sda5，uuid xxxxxxxxx 通过检查 blkid 和 lsblk -f 输出可以确定是正确的。列表中 sda5 后的 uuid yyyyyyyyyy 与 xxxxxxxxx 并不相同，但在 blkid 输出中可以看到它是 sda5 的 PARTUUID： 1234% sudo blkid/dev/sda5: UUID=&quot;xxxxxxxxx&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;yyyyyyyyyy&quot;/dev/loop1: TYPE=&quot;squashfs&quot;/dev/loop19: TYPE=&quot;squashfs&quot; PARTUUID 与 UUID 那么这里的 PARTUUID 是什么？ 其实 UUID 指的是 Filesystem UUID，即文件系统 UUID；相对的 PARTUUID 指的就是 Partition UUID，即分区的 UUID。顾名思义 Filesystem UUID 是储存在文件系统中的，而 Partition UUID 是储存在分区表中的。 Linux 中的大多数文件系统都支持 Filesystem UUID，例如 ext2/3/4、XFS。但 FAT 和 NTFS 对 UUID 的支持可能没有那么好。[1]如果没有一个可用的 initramfs 或者 initramfs 为空，内核就无法获取UUID（也不能获取 LABEL，即卷标）[2]。 实际上，内核并不会处理 UUID= 这种标识符，而是会忽略该选项，由 initramfs 中的工具（如 udev）发现 Filesystem UUID 对应的设备并切换 rootfs。 12345678910111213141516171819202122232425262728293031/* * Convert a name into device number. We accept the following variants: * * 1) &lt;hex_major&gt;&lt;hex_minor&gt; device number in hexadecimal represents itself * no leading 0x, for example b302. * 2) /dev/nfs represents Root_NFS (0xff) * 3) /dev/&lt;disk_name&gt; represents the device number of disk * 4) /dev/&lt;disk_name&gt;&lt;decimal&gt; represents the device number * of partition - device number of disk plus the partition number * 5) /dev/&lt;disk_name&gt;p&lt;decimal&gt; - same as the above, that form is * used when disk name of partitioned disk ends on a digit. * 6) PARTUUID=00112233-4455-6677-8899-AABBCCDDEEFF representing the * unique id of a partition if the partition table provides it. * The UUID may be either an EFI/GPT UUID, or refer to an MSDOS * partition using the format SSSSSSSS-PP, where SSSSSSSS is a zero- * filled hex representation of the 32-bit &quot;NT disk signature&quot;, and PP * is a zero-filled hex representation of the 1-based partition number. * 7) PARTUUID=&lt;UUID&gt;/PARTNROFF=&lt;int&gt; to select a partition in relation to * a partition with a known unique id. * 8) &lt;major&gt;:&lt;minor&gt; major and minor number of the device separated by * a colon. * 9) PARTLABEL=&lt;name&gt; with name being the GPT partition label. * MSDOS partitions do not support labels! * * If name doesn't have fall into the categories above, we return (0,0). * block_class is used to check if something is a disk name. If the disk * name contains slashes, the device name has them replaced with * bangs. */dev_t name_to_dev_t(const char *name) 上面内核源码中的注释说明了内核能够处理的几种设备标识符，其中并没有 UUID，大概看了下应该是在 md_setup_drive 中调用 name_to_dev_t 来解析标识符。 也可以尝试把 UUID 更改为一个不存在的值，最终控制台将输出如下内容： 1234567891011121314151617Begin: Loading essential drivers ... done.Begin: Running /scripts/init-premount ... done.Begin: Mounting root file system ... Begin: Running /scripts/local-top ... done.Begin: Running /scripts/local-premount ... done.Begin: Waiting for root file system ... Begin: Running /scripts/local-block ... done.done.Gave up waiting for root file system device. Common problems: - Boot args (cat /proc/cmdline) - Check rootdelay= (did the system wait long enough?) - Missing modules (cat /proc/modules; ls /dev)ALERT! UUID=50303285-93e1-49a2-92a0-24868766cff1 does not exist. Dropping to a shell!BusyBox v1.30.1 (Ubuntu 1:1.30.1-7ubuntu3) built-in shell (ash)Enter 'help' for a list of built-in commands.(initramfs) 很明显，这些输出内容是由 initramfs 中的程序或脚本输出的，内核本身并未输出错误信息。这也说明了 UUID= 标识符并非由内核处理。 内核中如果包含了所有所需的文件系统驱动，那么应该能够自行获得所有文件系统的 UUID，似乎并没有通过用户程序的必要。我也没有在网上发现这一做法的必要性的说法，因此推断该策略的目的可能是实现一定程度的解耦，毕竟正常情况下服务器系统都会加载 initramfs，而更精简的嵌入式领域则少有储存硬件变动的需求。通过用户程序控制该过程也能获得更多的灵活性。 这样看来，结合之前遇到的驱动问题，可以判断由于某些原因 initramfs 没有被正常加载，或者 initramfs 内容有误。 解决方案 A：让 grub 使用 PARTUUID 或路径 这里需要说明的是，使用 UUID 作为作为 rootfs 标识符是 grub 的默认行为。每当要从源码安装新内核时，一般做法是执行 make install，这背后执行了内核安装、DKMS模块编译、initramfs/initrd 生成、grub.cfg 生成等一系列操作。为了控制生成 grub.cfg 的默认行为，需要修改 /etc/default/grub 配置文件。 这里为了让 grub 在生成 grub.cfg 时使用路径（即 /dev/sdXX），可以在 /etc/default/grub 中添加： 1GRUB_DISABLE_LINUX_UUID=true 但如果服务器的硬盘连接顺序发生变化（或者其他可能改变硬件拓扑的情况），rootfs 在系统中的路径就可能发生变化（如从 /dev/sda5 变为 /dev/sdb5），导致系统无法启动。这也是 grub 默认使用 UUID 的原因。 因此我们可以选择使用 PARTUUID，从 grub 2.04 版本[3]开始，支持了一个新的选项 GRUB_DISABLE_LINUX_PARTUUID，通过与 GRUB_DISABLE_LINUX_UUID 结合可以让 grub 使用 PARTUUID 作为标识符[4]： 12GRUB_DISABLE_LINUX_UUID=trueGRUB_DISABLE_LINUX_PARTUUID=false 另外要注意的是，只有 GPT 分区表才有标准的 UUID。MBR 来说并没有一个真正的 UUID，它的 PARTUUID 要短得多，因为它实际上是 PTUUID + 分区编号。因为它们不够长，无法确保唯一性，并且无法保证分区一定存在 PARTUUID。具体解释参见：partition - Are UUIDs and PTUUIDs important for MBR disks? If so, how do I create them on my own? - Unix &amp; Linux Stack Exchange 分析 initramfs 加载 解决方案 A 只是治标不治本，initramfs 被正常加载才是我们最终的目标。 对比了 5.4.172 和 5.15.15 内核打印的区别，在 5.15.15 中找到两条关键打印： 123 RAMDISK: [mem 0x3900b000-0x3fffdfff]... Trying to unpack rootfs image as initramfs... 在内核中搜索了下，第一个打印来自于 reserve_initrd： 12345678910111213141516171819202122static void __init reserve_initrd(void){ /* Assume only end is not page aligned */ u64 ramdisk_image = get_ramdisk_image(); u64 ramdisk_size = get_ramdisk_size(); u64 ramdisk_end = PAGE_ALIGN(ramdisk_image + ramdisk_size); u64 mapped_size; if (!boot_params.hdr.type_of_loader || !ramdisk_image || !ramdisk_size) return; /* No initrd provided by bootloader */ initrd_start = 0; mapped_size = memblock_mem_size(max_pfn_mapped); if (ramdisk_size &gt;= (mapped_size&gt;&gt;1)) panic(&quot;initrd too large to handle, &quot; &quot;disabling initrd (%lld needed, %lld available)\\n&quot;, ramdisk_size, mapped_size&gt;&gt;1); printk(KERN_INFO &quot;RAMDISK: [mem %#010llx-%#010llx]\\n&quot;, ramdisk_image, ramdisk_end - 1); 准备在内核中加入一些打印调试下，结果发现这次生成的内核出现了 unpack initrd 的打印，但仍然无法使用 UUID 启动。 尝试在自己的 Ubuntu 22.04 LTS 虚拟机（并且软件包均更新到最新版本）上也安装了5.4.172内核，意外发现与服务器上的现象一致。通过串口将错误现场的内核打印输出到文件中，发现以下打印： 12[ 1.839668] Unpacking initramfs...[ 1.843910] Initramfs unpacking failed: invalid magic at start of compressed archive 出现了明确的错误，这就很好解决了。在网上查了下该错误，是因为目前较新的发行版都使用 zstd 作为 initramfs 压缩算法，而该算法在 5.10 内核中才得到支持。[5] 解决方案 B：配置使用 gzip 压缩 initramfs 对于 Ubuntu 来说，可以修改 /etc/initramfs-tools/initramfs.conf 文件，将 COMPRESS=zstd 修改为 COMPRESS=gzip[6]。再次执行 sudo make install 或者 sudo update-initramfs -c -k 5.4.172 即可。 在服务器上修改了下，可以使用 UUID 标识 rootfs 了。但服务器之前并没有 unpack 出错的打印，打印内容也不太一样，根据代码来看是启用了 CONFIG_BLK_DEV_RAM 的原因： 1234if (IS_ENABLED(CONFIG_BLK_DEV_RAM)) printk(KERN_INFO &quot;Trying to unpack rootfs image as initramfs...\\n&quot;);else printk(KERN_INFO &quot;Unpacking initramfs...\\n&quot;); 这个选项是给 initrd 使用的[7]，由于这里仅判断了该选项是否开启，所以和实际加载的是 initrd 还是 initramfs 并没有关系，这里我们使用的是 initramfs。 What UUIDs can do for you - Linux.com ↩︎ linux - Why can’t I specify my root fs with a UUID? - Unix &amp; Linux Stack Exchange ↩︎ GRUB/Configuration variables - Gentoo Wiki ↩︎ Gentoo Forums - How to make GRUB pass PARTUUID to the kernel ↩︎ Initramfs unpacking failed: invalid magic as start of compressed - Support - Manjaro Linux Forum ↩︎ boot - Having trouble with “Initramfs unpacking failed: Decoding failed” solutions - Ask Ubuntu ↩︎ Linux Kernel Driver DataBase: CONFIG_BLK_DEV_RAM: RAM block device support ↩︎","link":"/2024/05/18/initramfs_boot_fail/"},{"title":"小探 GI global-metadata","text":"算是博客的第一篇正式文章。 最近尝试了一下原神私服，在弄模型替换的时候出了点问题，正好借此机会对游戏做一点探索。 内容已过时！ 距本文撰写时已过去较长时间，最新版本的游戏保护方式已经升级，且这篇文章主要是我自己鼓捣的记录，目前已经没有什么价值了。 起因 想要在游戏中进行模型替换需要一个叫做 Melonloader 的框架，但这个框架在 2.7 版本中无法使用了[1]。查看产生的 log 可以发现该问题出在 Il2CppDumper 上： 1234567891011121314151617...[20:57:40.389] Executing Il2CppDumper...[20:57:40.392] &quot;C:\\Users\\Miguel\\Downloads\\GrassCutPer\\Genshin Impact\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\Il2CppDumper\\Il2CppDumper.exe&quot; &quot;C:\\Users\\Miguel\\Downloads\\GrassCutPer\\Genshin Impact\\Genshin Impact Game\\YuanShen_Data\\Native\\UserAssembly.dll&quot; &quot;C:\\Users\\Miguel\\Downloads\\GrassCutPer\\Genshin Impact\\Genshin Impact Game\\YuanShen_Data\\Native\\Data\\Metadata\\global-metadata.dat&quot;[20:57:40.766] Initializing metadata...[20:57:46.401] System.InvalidOperationException: 序列不包含任何元素[20:57:46.401] 在 System.Linq.Enumerable.Max[TSource](IEnumerable`1 source)[20:57:46.402] 在 Il2CppDumper.Metadata.&lt;&gt;c.&lt;ProcessingMetadataUsage&gt;b__38_0(KeyValuePair`2 x)[20:57:46.403] 在 System.Linq.Enumerable.WhereSelectEnumerableIterator`2.MoveNext()[20:57:46.404] 在 System.Linq.Enumerable.Max[TSource](IEnumerable`1 source)[20:57:46.405] 在 Il2CppDumper.Metadata.ProcessingMetadataUsage()[20:57:46.406] 在 Il2CppDumper.Metadata..ctor(Stream stream, StringDecryptionData decData, String nameTranslationPath)[20:57:46.407] 在 Il2CppDumper.Program.Init(String il2cppPath, String metadataPath, String nameTranslationPath, Metadata&amp; metadata, Il2Cpp&amp; il2Cpp)[20:57:46.408] 在 Il2CppDumper.Program.Main(String[] args)[20:57:46.419] Executing Il2CppAssemblyUnhollower......[20:57:46.516] [ERROR] 未经处理的异常: System.IO.DirectoryNotFoundException: 未能找到路径“C:\\Users\\Miguel\\Downloads\\GrassCutPer\\Genshin Impact\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\Il2CppDumper\\DummyDll”的一部分。... 经过一番搜索后，我发现这个 Il2CppDumper 实际上是被修改过的，原本的 Il2CppDumper 只能解析出 unity 正常生成的 global-metadata.dat，但游戏将 global-metadata.dat 文件进行了一些混淆，所以不将其解密是无法成功将元数据导出来的。Il2CppDumper 大概的作用就是把经过 Il2Cpp 转换后需要用到的符号还原出来并生成一系列 dll 文件，而 Melonloader 的运行应该需要用到这些 dll 文件。 这样看来应该是 2.7 版本的混淆方法有了变化，导致这个针对之前设计的 Il2CppDumper 没法正确解密了。虽然静等作者更新这个程序也不是不行，但刚好我之前有过探索下这个游戏背后的程序结构之类的想法，于是就打算自己分析分析看看能不能把这个解密方法修复下。 行为 用二进制编辑器看了下 metadata 文件，头部的标志已经没有了，和之前版本的对比了下也没看出来什么门道。我首先想到的是抓抓系统调用看看打开 metadata 文件的前后发生了些啥，然而抓了后又把 map/read 之类操作和 metadata 文件对了下，依然看不出什么东西，显然这种简单的分析是完全没用的。更诡异的是运行几次后连 read 都抓不到了，难不成这东西还有缓存的？ 分析 UserAssembly.dll 于是把 UserAssembly.dll 丢进 ida 分析了下。直接搜索字符串 global-metadata，找到了看起来可能是打开文件的地方： 于是我参考了网上相关文章研究了下，怀疑到下面有一处调用的解密函数，这个函数初始化在一个导出函数中，其中还初始化了另一个函数。 不过解密函数目前来看都不在这个 dll 中，四处翻了翻后我就暂时结束了对 UserAssembly.dll 的探索。 分析 Il2CppDumper 接下来我把目光转向了 Il2CppDumper，想通过它分析下之前版本的 metadata 是怎么解密出来的（没找到这个被修改过的 Il2CppDumper 源码）（更新：其实是有源码的，在另一个仓库）。于是把他丢进 ida，搜索打印的 log 字符串 “Initializing metadata…”，很快我就发现了一个叫做 DecryptMetadata 的函数，显然是解密函数： ida 好像反汇编不了 .net 的程序，换个反编译工具 dnSpy，这下源码基本完全解析出来了。首先动态调试了下，找到异常抛出的位置向前回溯，发现问题出自 header.metadataUsageListsCount 为 0，这个 header 又是通过之前解密的 metadata 数据初始化出来的，这样看 metadata 果然还是没有被正确解密。 12345public static MetadataDecryption.StringDecryptionData DecryptMetadata(byte[] metadata){ MetadataDecryption.DecryptMetadataBlocks(metadata); return MetadataDecryption.DecryptMetadataStringInfo(metadata);} 细看第一个解密函数 DecryptMetadataBlocks，先是从文件后部复制了点数据，之后做了个比较。奇怪的是这个比较通过了，我又在二进制编辑器里对了下这个值，确实是对的，看来加密逻辑没有变动太多？ 第一个解密函数12345678private static void DecryptMetadataBlocks(byte[] metadata){ byte[] array = new byte[16384]; Buffer.BlockCopy(metadata, metadata.Length - array.Length, array, 0, array.Length); if (array[200] != 46 || array[201] != 252 || array[202] != 254 || array[203] != 44) { throw new ArgumentException(&quot;*((uint32_t*)&amp;footer[0xC8]) != 0x2CFEFC2E&quot;); } 后面主要就是数据复制，用异或方法压缩出了一个 key，之后又异或了一堆奇怪的预定义的值。看来之前加密的逻辑主要还是异或，还用到了一些预先定义好的数据。到这里感觉从 Il2CppDumper 也不再能看出太多了。 搭建主程序调试环境 推测下解密函数很有可能应该在主程序 YuanShen.exe 里面了，研究了下找到个方法能通过调试器直接启动游戏本体进私服，方便之后调试。（更新：其实只要用的是 Fiddler 这种抓包软件就行了，效果一样且更方便） 修改 GrassClipper 的 scripts/private_server_launch.cmd，找到这里： 12:: Launch game&quot;%GAME_PATH%&quot; 把 &quot;%GAME_PATH%&quot; 这部分注释掉，加个 pause。之后启动先把 grasscutter 服务端跑起来，然后在命令行运行这个脚本，带上下面这些参数： 1private_server_launch.cmd 127.0.0.1 443 true &quot;&lt;YuanShen.exe 路径&gt;&quot; &quot;&lt;GrassClipper 路径&gt;&quot; false true 这里服务地址端口都是默认的配置，之后这个脚本会把代理开起来，接下来直接运行游戏本体就能进私服了，关闭记得在终端输入字符把剩下的关闭流程跑完，否则代理设置不会被清除掉没法正常联网。 搭好调试环境后，我发现这游戏主程序加了壳的没法直接调试（废话），想在游戏过程中挂 x64dbg 也挂不上，不知道用了什么魔法。另外游戏会不断检查并尝试杀掉 x64dbg 等调试器，启动时也会检查，以及如果杀不掉甚至游戏直接退出。所以这个部分遇到了点困难。 尝试新的 Il2CppDumper 回来更新文章了，发现已经有人更新了针对 2.7+ 版本的 Il2CppDumper[2]，所以尝试直接用它替换掉原本的 Il2CppDumper。 运行后 Il2CppDumper 成功生成了 DummyDll，但是还是有其他错误，下面是比较关键的部分： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[01:25:26.036] ------------------------------[01:25:26.037] Game Name: 原神[01:25:26.037] Game Developer: miHoYo[01:25:26.038] Unity Version: 2017.4.30f1[01:25:26.038] Game Version:[01:25:26.039] ------------------------------[01:25:26.379] Preferences Loaded![01:25:26.398] [Il2CppUnityTls] Patching mono_unity_get_unitytls_interface...[01:25:26.401] Loading Plugins...[01:25:26.409] ------------------------------[01:25:26.409] No Plugins Loaded![01:25:26.410] ------------------------------[libil2cpp] Failed to resolve 3441514353 at startup[libil2cpp] Failed to resolve 2641773275 at startup[libil2cpp] Failed to resolve 3753878500 at startup[libil2cpp] Failed to resolve 1688788800 at startup[libil2cpp] Failed to resolve 226400704 at startup[libil2cpp] Failed to resolve 58785463 at startup[libil2cpp] Failed to resolve 1939797683 at startup[libil2cpp] Failed to resolve 2903149294 at startup...[00:50:23.258] &quot;C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\Il2CppAssemblyUnhollower\\AssemblyUnhollower.exe&quot; &quot;--input=C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\Il2CppDumper\\DummyDll&quot; &quot;--output=C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\Il2CppAssemblyUnhollower\\Managed&quot; &quot;--mscorlib=C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Managed\\mscorlib.dll&quot; &quot;--unity=C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\Il2CppAssemblyGenerator\\UnityDependencies&quot; &quot;--gameassembly=C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\YuanShen_Data\\Native\\UserAssembly.dll&quot; &quot;--add-prefix-to=ICSharpCode&quot; &quot;--add-prefix-to=Newtonsoft&quot; &quot;--add-prefix-to=TinyJson&quot; &quot;--add-prefix-to=Valve.Newtonsoft&quot; &quot;--no-xref-cache&quot;[00:50:23.348] Reading assemblies... [00:50:23.538] Done in 00:00:00.1889345[00:50:23.539] Reading system assemblies... [00:50:23.552] Done in 00:00:00.0138266[00:50:23.553] Reading unity assemblies... [00:50:23.563] Done in 00:00:00.0100095[00:50:23.564] Creating rewrite assemblies... [00:50:23.584] Done in 00:00:00.0218627[00:50:23.585] Computing renames... [00:50:23.616] [ERROR] [00:50:23.657] [ERROR] 未经处理的异常: Mono.Cecil.AssemblyResolutionException: Failed to resolve assembly: 'System.Private.CoreLib, Version=5.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e'[00:50:23.658] [ERROR] 在 Mono.Cecil.BaseAssemblyResolver.Resolve(AssemblyNameReference name, ReaderParameters parameters)[00:50:23.659] [ERROR] 在 Mono.Cecil.DefaultAssemblyResolver.Resolve(AssemblyNameReference name)[00:50:23.659] [ERROR] 在 Mono.Cecil.MetadataResolver.Resolve(TypeReference type)[00:50:23.660] [ERROR] 在 Mono.Cecil.TypeReference.Resolve()[00:50:23.661] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.NameOrRename(TypeReference typeRef, RewriteGlobalContext context)[00:50:23.662] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.GenericNameToStrings(TypeReference typeRef, RewriteGlobalContext context)[00:50:23.663] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.GetUnobfuscatedNameBase(RewriteGlobalContext context, TypeDefinition typeDefinition, Boolean allowExtraHeuristics)[00:50:23.664] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.ProcessType(RewriteGlobalContext context, TypeDefinition originalType, Boolean allowExtraHeuristics)[00:50:23.665] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.ProcessType(RewriteGlobalContext context, TypeDefinition originalType, Boolean allowExtraHeuristics)[00:50:23.665] [ERROR] 在 AssemblyUnhollower.Passes.Pass05CreateRenameGroups.DoPass(RewriteGlobalContext context)[00:50:23.666] [ERROR] 在 AssemblyUnhollower.Program.Main(UnhollowerOptions options)[00:50:23.667] [ERROR] 在 AssemblyUnhollower.Program.Main(String[] args)[00:50:25.289] Done in 00:00:01.7042110[00:50:25.370] Loading Mods...[00:50:25.389] [ERROR] No MelonInfoAttribute Found in C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\Mods\\ClassLibrary3.dll...[00:50:25.499] [ERROR] Field internalEncoding was not found on class StreamWriter[00:50:25.500] [ERROR] Field internalStream was not found on class StreamWriter[00:50:25.502] [ERROR] Field iflush was not found on class StreamWriter[00:50:25.503] [ERROR] Field byte_buf was not found on class StreamWriter[00:50:25.504] [ERROR] Field byte_pos was not found on class StreamWriter[00:50:25.504] [ERROR] Field decode_buf was not found on class StreamWriter[00:50:25.505] [ERROR] Field decode_pos was not found on class StreamWriter[00:50:25.506] [ERROR] Field DisposedAlready was not found on class StreamWriter[00:50:25.506] [ERROR] Field preamble_done was not found on class StreamWriter[00:50:25.507] [ERROR] Field internalFormatProvider was not found on class TextWriter 这里放的 log 比较多，大部分内容在之前的 log 中也是有的，不同的部分在于 Il2CppDumper 生成 DummyDll 后接着又运行的 Il2CppAssemblyUnhollower 给出的错误。 从 trace 来看 AssemblyUnhollower 又用到了 Mono.Cecil 这个库，在该库中抛出了一个异常。除此之外开头部分的 libil2cpp 也还不清楚是谁打印的，这部分错误从一开始就存在，且没有被写入 log 文件中，可能比较特殊。 于是我又从网上找了一个 Il2CppAssemblyUnhollower 源码，这个原仓库应该是没了，链接的是镜像站。抱着试一试的心态编译了一下，发现并没有出现类似报错，不过出现了 methods failed to restore 的情况，不知道是否正常。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Reading assemblies...Done in 00:00:00.2249948Reading system assemblies...Done in 00:00:00.0138076Reading unity assemblies...Done in 00:00:00.0249082Creating rewrite assemblies...Done in 00:00:00.0095615Computing renames...Done in 00:00:00.0759375Creating typedefs...Done in 00:00:00.3707064Computing struct blittability...Done in 00:00:00.0270083Filling typedefs...Done in 00:00:00.0354803Filling generic constraints...Done in 00:00:00.0068350Creating members...Done in 00:00:04.5136379Scanning method cross-references...Done in 00:00:01.7303552Finalizing method declarations...Done in 00:00:10.20816800 total potentially dead methodsFilling method parameters...Done in 00:00:00.7021279Creating static constructors...Done in 00:00:02.1416967Creating value type fields...Done in 00:00:00.1698024Creating enums...Done in 00:00:00.0984626Creating IntPtr constructors...Done in 00:00:00.1559927Creating type getters...Done in 00:00:00.2090254Creating non-blittable struct constructors...Done in 00:00:00.0172973Creating generic method static constructors...Done in 00:00:00.0622003Creating field accessors...Done in 00:00:03.4009610Filling methods...Done in 00:00:03.5433611Generating implicit conversions...Done in 00:00:00.0293020Creating properties...Done in 00:00:00.2467474Unstripping types...Done in 00:00:00.0325269Unstripping fields...286 fields restored7 fields failed to restoreDone in 00:00:00.0090604Unstripping methods...7760 methods restored213 methods failed to restoreDone in 00:00:00.3213333Unstripping method bodies...IL unstrip statistics: 3567 successful, 594 failedDone in 00:00:00.1510770Generating forwarded types...Done in 00:00:00.0416483Writing xref cache...Done in 00:00:00.0073933Writing assemblies...Done in 00:00:10.7976969Writing method pointer map...Done in 00:00:00.1345476Done! 赶紧放到 MelonLoader 里试一下： 1234567891011121314151617181920[14:07:32.626] ------------------------------[14:07:32.627] 4 Mods Loaded[14:07:32.627] ------------------------------[14:07:32.628] Camera Tools v1.0.6[14:07:32.628] by portra[14:07:32.631] SHA256 Hash: 12464c1f24f4267a3f75afc6a26f2148b7b0fd6a7d2c9607f8dac0c91d20ac50[14:07:32.631] ------------------------------[14:07:32.632] HideUIScript v1.0.0[14:07:32.632] by Taiga74164[14:07:32.633] SHA256 Hash: 2b272e95f1062d01800c4da58f7dee800aeb8726a47ec2da02507bfa82c31640[14:07:32.634] ------------------------------[14:07:32.634] Model Changer v0.0.8[14:07:32.635] by portra[14:07:32.638] SHA256 Hash: dd7c505195b0ea8151945b7e1dc66a1583fa9488c6175808da6957fbe20ecde1[14:07:32.638] ------------------------------[14:07:32.638] UnityExplorer v4.9.0[14:07:32.639] by Sinai[14:07:32.663] SHA256 Hash: 09f49edd0be7c2c1aecbb892e360230094fd172acac51dce8f75557f3873946a[14:07:32.664] ------------------------------[14:07:32.668] [ERROR] No Support Module Loaded! 游戏成功启动，但是 UnityExplorer 并没有加载，log 如上，之前的错误中除了 libil2cpp 的报错都已经消失了。 看这个错误是 mod 不受支持，在 MelonLoader 源码中找到了该打印的来源： MelonLoader\\SupportModule\\SupportModule.cs12345if (Interface == null){ MelonLogger.Error(&quot;No Support Module Loaded!&quot;); return false;} 在里面加了一些打印： 12345678910111213[15:12:28.210] [ERROR] Found: System.Collections.Generic.List`1[MelonLoader.SupportModule+ModuleListing][15:12:28.210] [ERROR] Found: C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\SupportModules\\Il2Cpp.dll[15:12:28.211] [ERROR] Loading: C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\SupportModules\\Il2Cpp.dll[15:12:28.213] [ERROR] Support Module [Il2Cpp.dll] threw an Exception: System.Reflection.TargetInvocationException: Exception has been thrown by the target of an invocation. ---&gt; System.IO.FileNotFoundException: Could not load file or assembly 'netstandard, Version=2.1.0.0, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51' or one of its dependencies. at (wrapper managed-to-native) System.Reflection.MonoMethod.InternalInvoke(System.Reflection.MonoMethod,object,object[],System.Exception&amp;) at System.Reflection.MonoMethod.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) [0x00032] in &lt;e1319b7195c343e79b385cd3aa43f5dc&gt;:0 --- End of inner exception stack trace --- at System.Reflection.MonoMethod.Invoke (System.Object obj, System.Reflection.BindingFlags invokeAttr, System.Reflection.Binder binder, System.Object[] parameters, System.Globalization.CultureInfo culture) [0x00048] in &lt;e1319b7195c343e79b385cd3aa43f5dc&gt;:0 at System.Reflection.MethodBase.Invoke (System.Object obj, System.Object[] parameters) [0x00000] in &lt;e1319b7195c343e79b385cd3aa43f5dc&gt;:0 at MelonLoader.SupportModule.LoadInterface (System.String ModulePath) [0x00063] in &lt;20bb3b548fca4badbe0683004df1b626&gt;:0 at MelonLoader.SupportModule.Setup () [0x000c3] in &lt;20bb3b548fca4badbe0683004df1b626&gt;:0[15:12:28.214] [ERROR] Found: C:\\Users\\Miguel\\Downloads\\gi-priv\\games\\gi_2.7.0_self\\Genshin Impact Game\\MelonLoader\\Dependencies\\SupportModules\\Mono.dll[15:12:28.217] [ERROR] No Support Module Loaded! 看起来是和 Il2Cpp.dll 有关。 关于反调试 之前稍微试着用 x64dbg 调试了下，感觉它应该是通过 mhypbase.dll 这个东西实现反调试的，由他加载 mhyprot2.Sys 和 mhyprot3.Sys 这两个驱动。用 ScyllaHide 的默认配置似乎会导致程序跳到0地址。这方面经验不多就不写了。 更新：由于有其他事情很长时间没有再研究这个问题，之后应该不会更新这篇文章了。如果有新进展会另开一篇。 该问题的 Github Issue ↩︎ 2.7+ 版本的 Il2CppDumper ↩︎","link":"/2022/06/10/gi_research_metadata/"},{"title":"nvdimm 技术与编程模型概览","text":"nvdimm，即非易失性双列直插式内存模块（non-volatile DIMM），相对于传统的易失性内存，nvdimm 在断电后其中的内容也不会消失。 施工中！！！ 咕咕咕！ 定义于 ACPI（NFIT），UEFI（BTT），带外通信使用 DSM。 交错本来是传统易失性内存中的一个概念。N 代表数字，和 N 通道不是一个概念，只有交错后才能叫做 N 路. 理论 本节参考 Programming Models for Emerging Non-Volatile Memory Technologies 和 Persistent Memory Programming 这两篇文章，讲述几种理论上的持久化内存编程模型和有关的问题。文章中的 NVM 泛指各种非易失性内存设备。 编程模型 理论上有很多种可能的持久化内存编程模型，这里主要聚焦在最相关的的四种。NVM Block Mode 和 NVM File Mode 代表的是过去最常用的储存接口，PM Volume Mode 和 PM File Mode 则主要针对持久内存。 NVM Block Mode 上图表示了常见软件栈的一部分，红线表示了 NVM Block Mode 的接口，这里的接口指的是块读写接口。可以看到，在这个模型中驱动向文件系统等内核模块或直接向应用程序（如直接打开 /dev/sda1 设备）提供了传统块读写接口。为了使这种传统的接口更好的支持非易失性内存设备，可能需要对它进行功能上的扩展，以得到 I/O 性能的优化，例如一些原子操作的支持，向应用程序提供非易失性内存的某些属性等。通过将这种扩展标准化，能够为软件编写者提供一个更有效的生态系统来开发非易失性内存感知的应用程序。 NVM File Mode NVM File Mode 模式中主要关注的是应用程序和文件系统间的文件接口。和 NVM Block Mode 一样，为了更好的支持非易失性内存设备，文件接口可能需要进行一些扩展。 例如，MySQL 数据库的双重写入技术防止数据库在遇到电源故障等情况时，储存在文件中的数据表中的页面只被部分写入。如果数据库能够感知到硬件能够保证对于一定大小的页面写入不会因为系统中断导致撕裂，就可以避免双重写入的过程。为应用程序提供一个获取 powerfail write atomicity 的接口可以让程序自己决定合适的行为。 PM Volume Mode 如上图，在 PM Volume Mode 中，非易失性内存设备（NVM devices）是支持 PM 的，意味着设备可以通过处理器的 load 和 store 指令直接操作。尽管任何储存元件都可能通过一种处理器可以直接从中加载数据的方式连接到系统，但 NAND Flash 等技术会使处理器在加载时暂停，使得这种连接方式难以实现。更先进的非易失性内存设备和缓存技术使得这种方式成为可能。 在 PM Volume 模式下，内核组件可以直接访问持久内存区域。上图中红线标出的接口使得能够感知 PM 的内核模块和 NVM 驱动进行通信，这是为了让内核模块获取持久内存的物理地址范围。在这之后他就不再需要调用 NVM 驱动，而是直接通过地址访问持久内存。 PM File Mode PM File Mode 看起来和 NVM File Mode 有些相似，但不同的是这里的文件系统是感知 PM 的，可以看到这种文件系统就是通过上文的 PM Volume Mode 模型实现的。 感知 PM 的文件系统提供了所有传统文件系统会提供的文件接口，实际上它通常通过在已有的文件系统的基础上扩展 PM 感知能力来实现的。这种模式最主要的特点是，在使用 mmap 将一个文件 map 到内存空间时，应用程序可以绕过内核直接 load/store 持久内存，而在传统文件系统中文件 mmap 到内存中时需要使用 page cache 机制。 Persistent Memory 与 NVM Block Mode 和 NVM File Mode 的增量式改进不同，PM 的改进更具有颠覆性。正如 CPU 从提高频率到提高核心数量的转变时应用需要重新思考他们的算法并转向多线程编程一样，PM 结合了持久性和无需先进行块 I/O 的能力，它使我们重新思考数据结构以什么形式持久的储存。 申请 PM 内存 比较自然的想法是参考 malloc 设计一个对应的持久内存版本： 1ptr = pm_malloc(len); /* the naïve solution */ 看起来很合理，但很快我们就能发现其中的问题：应用之所以申请一段持久内存是为了持久的储存一些数据，因此应用需要一种方式来在重启后重新找到那片内存，因此应用需要给这片内存一个名字用于在下次重新找到它。有很多现成的命名方式供我们使用，例如对象 ID 或者类似 URL 的字符串。在命名后的下一个问题是如何确定应用有这片内存的访问权限，随着对 PM 管理方式的探究，还能发现更多问题，例如系统管理员如何修改 PM 权限、如何删除或重命名 PM、如何备份等等。对于传统储存，这些问题的答案是文件系统，所以尽管持久储存更像系统内存，以文件系统的形式暴露出来会是一个更方便的解决方案。文件 API 为 PM 区域提供了自然的命名空间，提供了创建、删除、重命名和调整大小的方法。当应用需要持久内存时，直接在感知 PM 的文件系统上打开或创建一个文件，并使用 mmap 将它映射到自己的地址空间即可。 持久化数据 需要储存的数据通常都会被缓存，并且需要通过某种同步 api 来将更改提交到储存介质。对于被映射到内存中的文件来说，msync 实现了该功能。传统 msync 将 page cache 中的数据刷新到储存中，而由于持久内存不需要 page cache，对应的 msync 调用的功能就变成了刷新 CPU cache 或其他保证数据被提交至电源故障安全的状态所需的中间步骤。 地址无关的数据结构 持久内存对于那些需要储存数组、树、堆等数据结构的应用来说很方便，应用可以利用文件 api 映射持久内存来直接访问这些结构。这带来了有关地址无关的数据结构的问题。 如上图，进程通过内存映射的方式访问持久内存，持久内存和其他映射到内存的文件（如共享库）一起被映射到内存空间中。各个区域之间有一些带状的空间（阴影部分区域），这片空间的具体大小通常是随机的，这是一种缓解某些类攻击的安全机制。这使得储存在持久内存上的数据结构中的指针会在第二次运行时变得无效，如上图的右侧部分所示。尽管这个问题在映射到内存的文件中就存在了，持久内存的出现使其变得更加普遍。 显而易见的解决方法是只储存相对 PM 的指针，这种方式需要每个指针解引用都清楚它是一个相对的指针并在其基础上加上一些偏移，因此比较容易出错。有运行时虚拟机或没有显式指针的语言可能可以透明的处理这种情形。一些编译器有 based pointer 这种特性，如微软的 C++ 编译器，使用特殊关键字声明的指针能够在解引用时根据基地址自动计算正确的值，使用起来更加方便。 错误处理 计算机系统的主存储器通常通过纠错码（ECC）等机制来防止错误。当该内存被应用程序使用时，应用程序通常不处理错误，可纠正的错误被纠正的过程对应用程序而言是透明的（这些错误通常被记录下来供管理员使用）。对于不可纠正的错误，操作系统在可能的情况下可以修复被破坏的应用程序内存（例如，如果内存内容没有被修改，可以重新从磁盘读取数据）。但总会有程序状态被破坏，无法安全的继续运行程序的情况。在大多数 UNIX 系统中，受影响的程序在这种情况下被杀死，UNIX 信号 SIGBUS 最常在此时被使用。 PM 的错误处理初看起来和内存相似，以在 Intel 架构上运行的 Linux 为例，内存错误是通过英特尔的 Machine Check Architecture（MCA）来报告的。当操作系统启用这一功能时，上图中的红色实心箭头显示了不可纠正错误的处理流程，当发生错误的位置被访问时，mcheck 模块会收到通知。 如之前所述，这时向应用程序发送 SIGBUS 信号可以让应用程序决定该做什么，然而由于这片区域是持久内存文件系统某个文件的一部分，即便应用程序会收到信号阻止它使用损坏的数据，也必须提供一个从这种情况中恢复的方法。系统管理员可能会尝试在更换有问题的 PM 之前备份文件系统中的其他数据，但是在我们目前所述的错误机制下，备份程序每次接触到损坏的位置都会收到一个 SIGBUS。在这种情况下，PM 感知的文件系统需要一种机制来接收错误通知，以便它能够隔离受影响的区域，继续提供对 PM 文件系统其余部分的访问。上图中的虚线箭头表示了这种机制，在启动时，文件系统告诉 mcheck 模块哪些 PM 地址范围是自己负责的，之后当错误发生时，文件系统会被 mcheck 模块调用来获得处理这个错误的机会。[1] 持久内存层的引入为应用程序开发人员提供了放置数据和数据结构的位置的新选择。传统上，数据被读取和写入易失性内存，然后刷新到非易失性持久存储。当应用程序启动时，必须先将数据从存储器中读取到易失性存储器中，然后才能对其进行访问。根据工作数据集的大小，这可能需要几秒钟、几分钟或几小时。通过巧妙的应用程序设计，开发人员和应用程序架构师现在可以利用这项新技术来提高性能并减少应用程序启动时间。持久内存引入了一些新的编程问题，这些问题不适用于传统的易失性内存。包括：数据持久性：在刷新之前，不能保证存储是持久的。尽管这对于已有数十年历史的内存映射文件 API（如 Linux 上的 mmap() 和 msync()）也是如此，但许多程序员还没有处理需要刷新到内存持久性的问题。遵循标准 API（如 msync() 刷新对持久性的更改）能够按预期工作。但是更优化的刷新使得应用程序直接从 CPU 缓存中刷新存储，而不是调用内核，也是可能的。 CPU 具有无序的 CPU 执行和缓存访问/刷新。这意味着如果应用程序存储了两个值，它们持久化的顺序可能不是应用程序写入它们的顺序。数据一致性： 8 字节存储在 x86 架构上是电源故障原子性的——如果在向对齐的 8 字节存储到 PMEM 期间发生电源故障，则在重新启动后该位置或者上旧的 8 字节或者是新的 8 字节（而不是两者的结合）。 x86 上大于 8 字节的任何内容都不是 powerfail atomic 的，因此需要由软件来实现一致性所需的任何事务/日志记录/恢复。请注意，这是特定于 x86 的——其他硬件平台可能具有不同的原子性大小（PMDK 的设计目的是让使用它的应用程序不必担心这些细节）。内存泄漏：持久存储的内存泄漏是持久的。重新启动服务器不会更改设备上的内容。在当前的 volatile 模型中，如果应用程序泄漏内存，重新启动应用程序或系统会释放该内存。字节级访问：应用开发者可以根据应用需求进行字节级别的读写。读/写不再需要对齐或等于存储块边界，例如：512byte、4KiB 或 8KiB。存储不需要读取整个块来修改几个字节，然后将整个块写回持久存储。应用程序可以根据需要随意读/写。这提高了性能并减少了内存占用开销。错误处理：应用程序可能需要直接检测和处理硬件错误。由于应用程序可以直接访问持久内存介质，因此任何错误都将作为内存错误返回给应用程序。 PMEM DAX BTT 实现 Linux 上关于持久内存的配置概念方面曾经有过一些变动，本章节将以本文撰写时最新内核和工具的支持情况为基础。 Programming Models for Emerging Non-Volatile Memory Technologies ↩︎","link":"/2022/07/18/nvdimm_intro/"},{"title":"序","text":"总之是本博客的第一篇文章。 大概是我建的第三个博客了，之前的几个因为各种原因现在连记录都已经没有了。第一个博客是大概 18 年 5 月，我在自己的主机上用 Wordpress 搭建的。和现在这个不同，当时用的是 .com 域名。但是之前实际上也没写什么东西出来，唯一一个比较可惜的是写过一篇关于 Windows 驱动的文章，现在也没有备份了。 之所以又建了这个博客是因为最近又觉得自己应该有一个能写些东西的地方，在已有的平台上写总感觉有些拘束，不如自己建一个更自由些。 这个博客是用 Hexo 搭建的，托管在 github 上，相对方便一些。 之后应该不会再把博客删掉了。","link":"/2022/05/28/preface/"},{"title":"Linux 内核网络中的 sk_buff 数据结构","text":"本文转载自 houmin.cc，原文已被删除，但因为之前阅读此文感觉说明较为清楚（后来查了下主要参考的是 Understanding Linux Network Internals 这本书），因此为方便今后查看，从 wayback machine 找到并转载了这篇文章。文章内容可能有补充修正。 在 Linux 内核的网络代码中，sk_buff 或许是最重要的数据结构，用来表示已接收或将要传输的数据。 sk_buff 定义在 include/linux/skbuff.h 中，它由许多变量组成，目标就是满足所有网络协议的需要。随着数据包在内核协议栈不同层次传递时，Linux 内核不是通过层与层之间的数据拷贝，而是通过追加头信息的方式，这即是 sk_buff 被使用的典型场景：在不同网络协议层之间移动，通过添加数据头的形式传递数据。本文分析采用的是 2.6.35 版本内核。 随着内核的迭代，sk_buff 的结构已经被添加了许多新的选项，已经存在的字段也被重新整理了很多遍。可将内部的字段分为以下几类： Layout 负责内存布局的字段 General 通用的字段 Feature-specific 对应特别功能字段 Management functions 一些用来管理 sk_buff 的函数 sk_buff 在不同的网络层次被使用（MAC 或其他在 L2 的协议，在 L3 的 IP 协议，在 L4 的 TCP 或 UDP 等），当它从一层传递到另一层时，各个字段也会发生变化。在被传递到 L3 之前，L4 会追加头信息，然后在被传递到 L2 之前，L3 会追加头信息。从一层传递到另一层时，通过追加头信息的方式比将数据在层之间拷贝会更有效率。由于要在 buff 的开头增加空间（与平时常见的在尾部追加空间相比）是一项复杂的操作，内核便提供了 skb_reserve 函数执行这个操作。因此，随着 buffer 从上层到下层的传递，每层协议做的第一件事就是调用 skb_reserve 去为它们的协议头在 buffer 的头部分配空间。在后面，我们将通过一个例子去了解内核如何在当 buffer 在各个层间传递时，确保为每一层保留了足够的空间让它们添加它们自己的协议头。 在接收数据时，buffer 会被从下层到上层传递，在从下到上的过程中，前一层的协议头对于当前层来说已经没有用了。比如：L2 的协议头只会被处理 L2 协议的设备驱动程序使用，L3 并不关心 L2 的头。那么内核怎么做的呢? 内核的实现是： sk_buff 中有一个指针会指向当前位于的层次的协议的协议头的内存开始地址，于是从 L2 到 L3 时，只需将指向 L2 头部的指针移动到 L3 的头部即可（又是一步追求效率的操作）。 Layout Fields Linux 内核把系统中所有的 sk_buff 实例维护在一个双向链表中。和任何双向链表类似，sk_buff 链表的每个节点也通过 next 和 prev 分别指向后继和前驱节点。但是 sk_buff 链表还要求：每个节点必须能够很快的找到整个链表的头节点。为了实现这个要求，一个额外的数据结构 sk_buff_head 被添加到链表的头部，作为一个空节点： 12345678struct sk_buff_head { /* These two members must be first. */ struct sk_buff *next; struct sk_buff *prev; __u32 qlen; // 表示链表中的节点数，当前的sk_buff链上包含多少个skb spinlock_t lock; // 加锁，防止对表的并发访问}; sk_buff 和 sk_buff_head 开始的两个字段是相同的，都是 next 和 prev 指针。即使 sk_buff_head 比 sk_buff 更轻量化，也允许这两种结构在链表中共存。另外，可以使用相同函数来操作 sk_buff 和 sk_buff_head。 为了实现通过每个节点都能快速找到链表头，每个节点都会包含一个指向链表中唯一的 sk_buff_head 的指针（list）。 下面是 layout 字段的详细解释： 1234567891011121314151617181920212223242526struct sk_buff { /* These two members must be first. */ struct sk_buff *next; struct sk_buff *prev; struct sock *sk; // 表示从属于那个socket，主要是被4层用到。 /* ... */ unsigned int len, // 表示在 buffer 中数据区域的大小, 值会随着 buffer 在各层间传递而改变 data_len; // 和 len 不同的是，data_len 只记录分段中的数据大小 __u16 mac_len, // MAC 头部的长度 hdr_len; // header len void (*destructor)(struct sk_buff *skb); // skb的析构函数，一般都是设置为sock_rfree或者sock_wfree /* ... */ /* These elements must be at the end, see alloc_skb() for details. */ sk_buff_data_t tail; sk_buff_data_t end; unsigned char *head, *data; unsigned int truesize; // 表示整个skb的大小, 包括skb本身以及数据, 也就是 len+sizeof(struct sk_buff) atomic_t users; // sk_buff 的引用计数}; head 、end 、data 和 tail 这 4个指针用来表示 buffer 中数据域的边界。当每一层为了任务而准备 buffer 时，为了协议头或数据，可能会分配更多的空间。 head 和 end 指向了 buffer 被分配的内存区域的开始和结束， data 和 tail 指向真实数据的开始和结束。 每一层能够在 head 和 data 之间的区域填充协议头，或者在 tail 和 end 之间的区域填充新的数据。 General Fields 在 sk_buff 中存在一些通用目的的字段，这些字段没有与特定的内核功能绑定： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748struct sk_buff { /* ... */ struct skb_timeval tstamp; // 时间戳，表示何时被接收或有时表示包预定的传输时间 struct net_device *dev; // 描述一个网络设备，之后会专门分析 sk_buff_data_t transport_header; // L4 协议栈的协议头 sk_buff_data_t network_header; // L3 协议栈的协议头 sk_buff_data_t mac_header; // L2 协议栈的协议头 struct dst_entry *dst; // 由路由子系统使用，据说数据结构比较复杂 /* * This is the control buffer. It is free to use for every * layer. Please put your private variables there. If you * want to keep them across layers you have to do a skb_clone() * first. This is owned by whoever has the skb queued ATM. */ char cb[48]; // control buffer, 后面详细分析 // 校验相关 union { __wsum csum; struct { __u16 csum_start; __u16 csum_offset; }; }; __u32 priority; // 优先级，主要用于QoS // 一些标识位 kmemcheck_bitfield_begin(flags1); __u8 local_df:1, // 是否可以本地切片的标志 cloned:1, // 设置后表示此结构是另一个sk_buff缓冲区的克隆 ip_summed:2, // 这个表示校验相关的一个标记,表示硬件驱动是否为我们已经进行了校验 nohdr:1, // 这个域如果为1,则说明这个skb的头域指针已经分配完毕，因此这个时候计算头的长度只需要head和data的差就可以了 nfctinfo:3; __u8 pkt_type:3, // 主要是表示数据包的类型，比如多播，单播，回环等等，可在 include/linux/if_packet.h 中查看 fclone:2, // 这个域是一个clone标记，主要是在fast clone中被设置 ipvs_property:1, // ipvs 相关 peeked:1, // udp 相关，表示只是查看数据 nf_trace:1; // netfilter 相关 kmemcheck_bitfield_end(flags1); __be16 protocol; // 从 L2 处的网卡设备驱动程序的角度来看，在更高层次上使用的协议，完整列表可在 include/linux/if_ether.h /* ... */}; transport_header、network_header 和 mac_header 分别为 L4 、L3 和 L2 的协议头。和之前版本比较有了变化，不再是联合体，使用更加方便了，Linux给出了很方便的函数直接定位到各层的头部。下图是2.4版本的，只是说明了数据包在不同协议层移动时 data 指针的处理。 当接收到数据包时，负责处理第 n 层协议头的函数从第 n-1 层接收一个 buffer，其中skb-&gt;data 指向第 n 层协议头的开头。 处理第 n 层的函数会为此层初始化适当的指针（例如，L3 的处理函数会为 skb-&gt;nh 赋值）以保留 skb-&gt;data 字段，因为当 skb-&gt;data 被赋值为 buffer 内的其他偏移量时，该指针的内容将在下一层的处理过程中丢失。 该函数完成第 n 层的处理，并在将数据包传递到第 n+1 层处理程序之前，更新 skb-&gt;data 使其指向第 n 层协议头的末尾（即第 n+1 层协议头的开始位置） 下面说一下 control buffer ，它用来存储一些私有信息，由各层维护以供内部使用。它是在 sk_buff 结构中静态分配的（当前大小为40个字节），并且足够大以容纳每一层所需的任何私有数据。在每一层的代码中，访问都是通过宏进行的，以使代码更具可读性。例如，TCP使用该空间存储 tcp_skb_cb 数据结构，该数据结构在 include/net/tcp.h 中定义： 12345678struct tcp_skb_cb { //... __u32 seq; /* Starting sequence number */ __u32 end_seq; /* SEQ + FIN + SYN + datalen */ __u8 tcp_flags; /* TCP header flags. (tcp[13]) */ __u32 ack_seq; /* Sequence number ACK'd */ //...}; 这是 TCP 代码访问结构的宏，宏仅由一个指针转换组成： 1#define TCP_SKB_CB(__skb) ((struct tcp_skb_cb *)&amp;((__skb)-&gt;cb[0])) 这是一个示例，其中 TCP 模块在收到分段后填写 cb 结构： 123456789static void tcp_v4_fill_cb(struct sk_buff *skb, const struct iphdr *iph, const struct tcphdr *th) { TCP_SKB_CB(skb)-&gt;seq = ntohl(th-&gt;seq); TCP_SKB_CB(skb)-&gt;end_seq = (TCP_SKB_CB(skb)-&gt;seq + th-&gt;syn + th-&gt;fin + skb-&gt;len - th-&gt;doff * 4); TCP_SKB_CB(skb)-&gt;ack_seq = ntohl(th-&gt;ack_seq); TCP_SKB_CB(skb)-&gt;tcp_flags = tcp_flag_byte(th); TCP_SKB_CB(skb)-&gt;tcp_tw_isn = 0; TCP_SKB_CB(skb)-&gt;ip_dsfield = ipv4_get_dsfield(iph); TCP_SKB_CB(skb)-&gt;sacked = 0;} Feature-Specific Fields Linux内核是模块化的，允许你选择要包括的内容和要忽略的内容。因此，只有在编译内核时开启支持像 Netfilter 或 QoS 之类的特定功能的情况下，某些字段才会包含在 sk_buff 数据结构中： 12345678910111213141516171819struct sk_buff { /* ... */#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE) struct nf_conntrack *nfct; struct sk_buff *nfct_reasm;#endif#ifdef CONFIG_BRIDGE_NETFILTER struct nf_bridge_info *nf_bridge;#endif#ifdef CONFIG_NET_SCHED __u16 tc_index; /* traffic control index */#ifdef CONFIG_NET_CLS_ACT __u16 tc_verd; /* traffic control verdict */#endif#endif /* ... */}; Management Functions 内核提供了许多很简短的简单函数来操纵 sk_buff 节点或链表。如果查看文件 include/linux/skbuff.h 和 net/core/skbuff.c，你会发现几乎所有功能都有两个版本，名称分别为 do_something 和 __do_something。通常，第一个是包装函数，它在对第二个调用的周围添加了额外的健全性检查或锁定机制。内部 __do_something 函数通常不直接调用。该规则的例外通常是编码不良的函数，这些函数最终将被修复。 内存分配 alloc_skb alloc_skb 是分配缓冲区的主要函数，在 net/core/skbuff.c 中定义。 __alloc_skb 分配缓冲区和一个 sk_buff 结构，这个函数起始可以看作三部分： 第一部分是分配内存，由于数据缓冲区和 sk_buff 自身是两个不同的结构，所以创建单个缓冲区涉及两个内存分配 调用函数 kmem_cache_alloc 从缓存中获取 sk_buff 数据结构 调用 kmalloc 获取数据缓冲区，而 kmalloc 也会使用缓存的内存（如果可用） 第二部分是初始化分配的 skb 的相关域 第三部分是处理 fclone 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465struct sk_buff *__alloc_skb(unsigned int size, gfp_t gfp_mask, int fclone, int node){ struct kmem_cache *cache; struct skb_shared_info *shinfo; struct sk_buff *skb; u8 *data; cache = fclone ? skbuff_fclone_cache : skbuff_head_cache; /* Get the HEAD */ // 申请 sk_buff 数据结构的内存 skb = kmem_cache_alloc_node(cache, gfp_mask &amp; ~__GFP_DMA, node); if (!skb) goto out; prefetchw(skb); size = SKB_DATA_ALIGN(size); // 申请数据区域的内存 data = kmalloc_node_track_caller(size + sizeof(struct skb_shared_info), gfp_mask, node); if (!data) goto nodata; prefetchw(data + size); /* * Only clear those fields we need to clear, not those that we will * actually initialise below. Hence, don't put any more fields after * the tail pointer in struct sk_buff! */ memset(skb, 0, offsetof(struct sk_buff, tail)); skb-&gt;truesize = size + sizeof(struct sk_buff); atomic_set(&amp;skb-&gt;users, 1); skb-&gt;head = data; skb-&gt;data = data; skb_reset_tail_pointer(skb); skb-&gt;end = skb-&gt;tail + size; kmemcheck_annotate_bitfield(skb, flags1); kmemcheck_annotate_bitfield(skb, flags2);#ifdef NET_SKBUFF_DATA_USES_OFFSET skb-&gt;mac_header = ~0U;#endif /* make sure we initialize shinfo sequentially */ shinfo = skb_shinfo(skb); memset(shinfo, 0, offsetof(struct skb_shared_info, dataref)); atomic_set(&amp;shinfo-&gt;dataref, 1); if (fclone) { struct sk_buff *child = skb + 1; atomic_t *fclone_ref = (atomic_t *) (child + 1); kmemcheck_annotate_bitfield(child, flags1); kmemcheck_annotate_bitfield(child, flags2); skb-&gt;fclone = SKB_FCLONE_ORIG; atomic_set(fclone_ref, 1); child-&gt;fclone = SKB_FCLONE_UNAVAILABLE; }out: return skb;nodata: kmem_cache_free(cache, skb); skb = NULL; goto out;} 在调用 kmalloc 之前，使用宏 SKB_DATA_ALIGN 调整了大小参数以强制对齐。返回之前，该函数将初始化结构体中的一些参数，从而产生下图所示的最终结果： 在图右侧存储块的底部，可以看到为了强制对齐而引入的 Padding 区域。 skb_shared_info 块主要用于处理 IP 的分片（IP 协议根据 MTU 和 MSS 对数据包进行的分片传输）。 __alloc_skb 函数可以叫做 Fast SKB cloning 函数，这个函数存在的主要原因是，以前我们每次 skb_clone 一个 skb 的时候，都是要调用 kmem_cache_alloc 从 cache 中 alloc 一块新的内存。而现在当我们拥有了 fast clone 之后，通过调用 alloc_skb_fclone 函数来分配一块大于 sizeof(struct sk_buff) 的内存，也就是在这次请求的 skb 的下方多申请了一些内存，然后返回的时候设置返回的 skb 的 fclone 标记为 SKB_FCLONE_ORIG，而多申请的那块内存的 sk_buff 的 fclone 为 SKB_FCLONE_UNAVAILABLE，这样当我们调用 skb_clone 克隆这个 skb 的时候看到 fclone 的标记就可以直接将 skb 的指针+1,而不需要从 cache 中取了。这样的话节省了一次内存存取，提高了 clone 的效率，不过调用 flcone 一般都是我们确定接下来这个 skb 会被 clone 很多次。 更详细的 fclone 的介绍可以看这里。 dev_alloc_skb dev_alloc_skb() 也是一个缓冲区分配函数，它主要被设备驱动接收数据包时使用，通常用在中断上下文中。这是一个 alloc_skb() 的包装函数，它会在请求分配的大小上增加 NET_SKB_PAD 字节的空间以优化缓冲区的读写效率，它的分配要求使用 gfp_mask，为调用函数指定。 12345678// allocate an skbuff for receivingstatic inline struct sk_buff *__dev_alloc_skb(unsigned int length, gfp_t gfp_mask){ struct sk_buff *skb = alloc_skb(length + NET_SKB_PAD, gfp_mask); if (likely(skb)) skb_reserve(skb, NET_SKB_PAD); return skb;} 内存释放 kfree_skb kfree_skb 只有 skb-&gt;users 计数器为1时才释放，这里主要是判断一个引用标记位 users，将它减一，如果大于0则直接返回，否则释放 skb。 1234567891011void kfree_skb(struct sk_buff *skb){ if (unlikely(!skb)) return; if (likely(atomic_read(&amp;skb-&gt;users) == 1)) smp_rmb(); else if (likely(!atomic_dec_and_test(&amp;skb-&gt;users))) return; trace_kfree_skb(skb, __builtin_return_address(0)); __kfree_skb(skb);} kfree_skb 仅在 skb-&gt;users 计数器为1时（没有缓冲区的用户时）才释放缓冲区。 否则，该函数只会使该计数器递减。因此，如果一个缓冲区有三个用户，则只有当调用第三次 dev_kfree_skb 或 kfree_skb 时才会真正释放内存。 数据保留和对齐 skb_put：在数据域尾部追加一段空间 skb_push：在数据域的头部追加一段空间 skb_pull：将 skb-&gt;data 指针在数据域下移指定字节 skb_reserve：在 sk_buff 中 skb-&gt;data 之前的空间追加一段空间（在每层追加自己的协议头时常用到） 下图为分别对 sk_buff 执行 skb_put(a)，skb_push(b)，skb_pull©，skb_reserve(d) 的前后对比： skb_put 先来看 __skb_put 函数，可以看到它只是将 tail 指针移动 len 个位置，然后 len 也相应的增加 len 个大小。 以下均在 /include/linux/skbuff.h 中： 12345678static inline unsigned char *__skb_put(struct sk_buff *skb, unsigned int len){ unsigned char *tmp = skb_tail_pointer(skb); SKB_LINEAR_ASSERT(skb); skb-&gt;tail += len; skb-&gt;len += len; return tmp;} skb_push __skb_push 是将 data 指针向上移动 len 个位置，对应的 len 肯定也是增加 len 大小。 123456static inline unsigned char *__skb_push(struct sk_buff *skb, unsigned int len){ skb-&gt;data -= len; skb-&gt;len += len; return skb-&gt;data;} skb_pull __skb_pull 是将 data 指针向下移动 len 个位置，然后 len 减小 len 大小 123456static inline unsigned char *__skb_pull(struct sk_buff *skb, unsigned int len){ skb-&gt;len -= len; BUG_ON(skb-&gt;len &lt; skb-&gt;data_len); return skb-&gt;data += len;} skb_reserve __skb_reserve 是将整个数据区，也就是 data 以及 tail 指针一起向下移动 len 大小。skb_reserve 在缓冲区的头部保留一些空间，通常用于允许插入协议头或强制将数据在某个边界上对齐。 12345static inline void skb_reserve(struct sk_buff *skb, int len){ skb-&gt;data += len; skb-&gt;tail += len;} 注意，skb_reserve 函数实际上并没有将任何内容移入或移出数据缓冲区，它只是更新两个指针。 查看以太网网卡驱动程序的代码（比如: drivers/net/ethernet/3com/3c59x.c vortex_rx 函数），你能看到它们在将任何数据存储在他们刚刚分配的缓冲区中之前都会使用以下命令： 1skb_reserve(skb, 2); /* Align IP on 16 byte boundaries */ 因为他们知道他们将要把协议头为 14 个字节的以太网帧复制到缓冲区中，所以参数 2 将缓冲区的 head 指针下移了 2 个字节。这将让紧跟在以太网头之后的 IP 头，从缓冲区的开头在 16 字节边界上对齐。 下图展示了 skb_reserve 在数据从上到下传递（发送数据）时的作用（为下层协议在数据区的头部分配空间）： 当要求 TCP 传输某些数据时，它会按照某些条件（TCP Max Segment Size(mss)，对分散收集 I/O 支持等）分配一个缓冲区。 TCP 在缓冲区的头部保留（通过调用 skb_reserve）足够的空间，以容纳所有层（TCP，IP，Link 层）的所有协议头。参数 MAX_TCP_HEADER 是所有级别的所有协议头的总和，并考虑到最坏的情况：因为 TCP 层不知道将使用哪种类型的接口进行传输，因此它为每个层保留最大的标头。它甚至考虑到多个 IP 协议头的可能性（因为当内核编译为支持 IP in IP 时，你可以拥有多个IP 协议头）。 TCP 的 payload （应用层传输的数据）被复制到缓冲区中。请注意上图只是个例子，TCP 的 payload 可以被不同地组织，例如可以将其存储为片段。 TCP 层添加它的协议头。 TCP 层将缓冲区移交给 IP 层，IP层也添加协议头。 IP 层将缓冲区移交给下一层，下一层也添加它的协议头。 请注意，当缓冲区在网络栈中向下移动时，每个协议会将 skb-&gt;data 指针向下移动，在其协议头中复制，并更新 skb-&gt;len。 skb_push 将一个数据块添加到缓冲区的开头，而 skb_put 将一个数据块添加到末尾。像 skb_reserve 一样，这些函数实际上并不会向缓冲区添加任何数据。他们只是将指针移到它的头或尾，数据填充应该由其他功能显式操作。skb_pull 通过将 head 指针向前移动来从缓冲区的头中删除数据块。 skb_shared_info 结构体 &amp; skb_shinfo 函数 在上面网卡驱动拷贝帧到缓冲区的例子中出现过 skb_shared_info。它是用来保留与数据域有关的其他信息。这个数据结构紧跟在标记数据域结束的 end 指针后面。 1234567struct skb_shared_info { atomic_t dataref; // 代表数据域的用户数（数据域被引用的次数） __u8 nr_frags; // 用于 ip fragmetation struct sk_buff *frag_list; // 用于 ip fragmetation skb_frag_t frags[MAX_SKB_FRAGS]; // 用于 ip fragmetation //...}; skb_is_nonlinear 函数可用于检查缓冲区是否已分段，而 skb_linearize 函数可用于将多个片段合为单个缓冲区。 sk_buff 中没有专门的指针指向 skb_shared_info 区域，skb_shinfo 函数就是方便得到指向 skb_shared_info 区域指针的函数: 123456#define skb_shinfo(SKB) ((struct skb_shared_info *)(skb_end_pointer(SKB)))static inline unsigned char *skb_end_pointer(const struct sk_buff *skb){ return skb-&gt;end;} 克隆和拷贝 skb_clone 当相同的缓冲区需要由不同的消费者处理，并且他们可能更改 sk_buff 结构中的内容时，为了提高效率，内核并没有克隆缓冲区的结构和数据域，而是仅复制 sk_buff 的结构，并使用引用计数进行操作，以避免过早释放共享数据块。skb_clone 函数负责拷贝一个 buffer。使用克隆的一种情况是，需要将入口数据包分发给多个接收者，例如协议处理程序和一个或多个网络分接头（Network taps）。 sk_buff 克隆不会链接到任何链表，也没有引用套接字所有者。克隆和原始缓冲区中的 skb-&gt;cloned 字段均设置为1。在克隆中将 skb-&gt;users 设置为1，以便第一次尝试删除它（被克隆的 sk_buff）时会成功，并且数据域的引用数（dataref）递增（因为现在有一个新的 sk_buff 指向了）。 skb_clone 会调用 __skb_clone: 1234567891011121314151617181920212223static struct sk_buff *__skb_clone(struct sk_buff *n, struct sk_buff *skb) {#define C(x) n-&gt;x = skb-&gt;x // 定义的宏，如果 x 是普通变量则是值赋值// 如果 x 是指针，则是指向同一块区域 n-&gt;next = n-&gt;prev = NULL; n-&gt;sk = NULL; __copy_skb_header(n, skb); //... n-&gt;destructor = NULL; C(tail); C(end); C(head); C(head_frag); C(data); // data 是一个指针, 所以没有克隆数据域，只是指向了数据域的内存地址 C(truesize); refcount_set(&amp;n-&gt;users, 1); //设置克隆的 sk_buff 的用户数为1 atomic_inc(&amp;(skb_shinfo(skb)-&gt;dataref)); //增加数据域的引用次数 skb-&gt;cloned = 1; return n;#undef C} 下图为一个被分段（一个缓冲区，其中一些数据存储在与 frags 数组链接的数据片段中）了的缓冲区克隆的例子: pskb_copy 与 skb_copy 当缓冲区被克隆时，无法修改数据块的内容。这意味着代码无需做同步保证即可访问数据。但是，当一个函数不仅需要修改 sk_buff 结构的内容，还需要修改数据域时，就必须要克隆数据域了。如果真要修改数据域，开发者也有两个选项可用： 当开发者知道自己仅仅需要修改的数据在 skb-&gt;start 和 skb-&gt;end 的区域时，开发者可以使用 pskb_copy 方法只克隆那个区域。 当开发者认为自己或许也需要修改分段数据域时，也就是 skb_shared_info，就必须使用 skb_copy。 pskb_copy 和 skb_copy 的不同如下图中的(a)和(b): 在决定克隆或复制缓冲区时，每个子系统的程序员都无法预料其他内核组件（或其子系统的其他用户）是否需要该缓冲区中的原始信息。内核是非常模块化的，并且以非常动态和不可预测的方式进行更改，因此每个子系统都不知道其他子系统可以使用缓冲区做什么。因此，每个子系统的程序员只需跟踪他们对缓冲区所做的任何修改，并注意在修改任何内容之前先进行复制，以防内核的其他部分需要原始信息。 队列管理函数 有一些函数用来维护 sk_buff 双向链表（也可以称为队列 queue）中的节点。下面是一些常用的功能函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// skb_queue_head - queue a buffer at the list headvoid skb_queue_head(struct sk_buff_head *list, struct sk_buff *newsk){ unsigned long flags; spin_lock_irqsave(&amp;list-&gt;lock, flags); __skb_queue_head(list, newsk); spin_unlock_irqrestore(&amp;list-&gt;lock, flags);}// skb_queue_tail - queue a buffer at the list tailvoid skb_queue_tail(struct sk_buff_head *list, struct sk_buff *newsk){ unsigned long flags; spin_lock_irqsave(&amp;list-&gt;lock, flags); __skb_queue_tail(list, newsk); spin_unlock_irqrestore(&amp;list-&gt;lock, flags);}// skb_dequeue - remove from the head of the queuestruct sk_buff *skb_dequeue(struct sk_buff_head *list){ unsigned long flags; struct sk_buff *result; spin_lock_irqsave(&amp;list-&gt;lock, flags); result = __skb_dequeue(list); spin_unlock_irqrestore(&amp;list-&gt;lock, flags); return result;}// skb_dequeue_tail - remove from the tail of the queuestruct sk_buff *skb_dequeue_tail(struct sk_buff_head *list){ unsigned long flags; struct sk_buff *result; spin_lock_irqsave(&amp;list-&gt;lock, flags); result = __skb_dequeue_tail(list); spin_unlock_irqrestore(&amp;list-&gt;lock, flags); return result;}// skb_queue_purge - empty a listvoid skb_queue_purge(struct sk_buff_head *list){ struct sk_buff *skb; while ((skb = skb_dequeue(list)) != NULL) kfree_skb(skb);} 操作队列的所有函数都必须保证是原子操作。也就是说，它们必须获取 sk_buff_head 结构提供的队列自旋锁。否则，它们可能会被异步事件中断，这些异步事件会使队列中的元素入队或出队，例如到期计时器调用的函数会导致争用条件。 参考资料 Linux Foundation Wiki: sk_buff Understanding Linux Network Internals: Section 2.1. The Socket Buffer: sk_buff Structure","link":"/2023/04/21/skbuff_repost/"}],"tags":[{"name":"网络","slug":"网络","link":"/tags/%E7%BD%91%E7%BB%9C/"},{"name":"逆向","slug":"逆向","link":"/tags/%E9%80%86%E5%90%91/"},{"name":"代理","slug":"代理","link":"/tags/%E4%BB%A3%E7%90%86/"},{"name":"Bonjour","slug":"Bonjour","link":"/tags/Bonjour/"},{"name":"内核","slug":"内核","link":"/tags/%E5%86%85%E6%A0%B8/"},{"name":"调度器","slug":"调度器","link":"/tags/%E8%B0%83%E5%BA%A6%E5%99%A8/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"clangd","slug":"clangd","link":"/tags/clangd/"},{"name":"llvm","slug":"llvm","link":"/tags/llvm/"},{"name":"initramfs","slug":"initramfs","link":"/tags/initramfs/"},{"name":"游戏","slug":"游戏","link":"/tags/%E6%B8%B8%E6%88%8F/"},{"name":"硬件","slug":"硬件","link":"/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"nvdimm","slug":"nvdimm","link":"/tags/nvdimm/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"sk_buff","slug":"sk-buff","link":"/tags/sk-buff/"}],"categories":[{"name":"逆向","slug":"逆向","link":"/categories/%E9%80%86%E5%90%91/"},{"name":"内核","slug":"内核","link":"/categories/%E5%86%85%E6%A0%B8/"},{"name":"杂谈","slug":"杂谈","link":"/categories/%E6%9D%82%E8%B0%88/"},{"name":"硬件","slug":"硬件","link":"/categories/%E7%A1%AC%E4%BB%B6/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"}],"pages":[{"title":"","text":"","link":"/404.html"},{"title":"友链","text":"Moeka 小莫のBase","link":"/links.html"},{"title":"关于","text":"关于我 浮枕，之前用过很长一段时间的名字是 Miguel Duarte，现在主要作为网上的英文名。换成现在这个名字的主要是因为想有一个好记的中文网名，灵感来自于英文 fusion，改成了和它发音相似又给我感觉比较好听的中文。 很喜欢幾原邦彥。 许可 本站 logo 和 404 页面图片来源于 freepik，并经过修改。 Planet vector created by pikisuperstar - www.freepik.com 404 vector created by freepik - www.freepik.com","link":"/about.html"}]}